{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from keras.layers import Dropout, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 불러오기\n",
    "* Kaggle의 필터링 된 버전의 Dogs vs Cats 데이터 세트를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
      "68608000/68606236 [==============================] - 26s 0us/step\n",
      "C:\\Users\\seoul it\\.keras\\datasets\\cats_and_dogs_filtered\n"
     ]
    }
   ],
   "source": [
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seoul it\\.keras\\datasets\\cats_and_dogs_filtered\\train\n",
      "C:\\Users\\seoul it\\.keras\\datasets\\cats_and_dogs_filtered\\validation\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.join(PATH, 'train')            # 학습용\n",
    "val_dir = os.path.join(PATH, 'validation')  # 평가용\n",
    "print(train_dir)\n",
    "print(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개 :  C:\\Users\\seoul it\\.keras\\datasets\\cats_and_dogs_filtered\\train\n",
      "고양이 :  C:\\Users\\seoul it\\.keras\\datasets\\cats_and_dogs_filtered\\validation\n",
      "개 :  C:\\Users\\seoul it\\.keras\\datasets\\cats_and_dogs_filtered\\validation\\dogs\n",
      "고양이 :  C:\\Users\\seoul it\\.keras\\datasets\\cats_and_dogs_filtered\\validation\\cats\n"
     ]
    }
   ],
   "source": [
    "# 개, 고양이 학습, 평가 폴더 경로\n",
    "print(\"개 : \", train_dir)\n",
    "print(\"고양이 : \", val_dir)\n",
    "\n",
    "# 개, 고양이 평가용 폴더 경로 \n",
    "val_dogs_dir = os.path.join(val_dir, 'dogs')  # directory with our validation dog pictures\n",
    "val_cats_dir = os.path.join(val_dir, 'cats')  # directory with our validation cat pictures\n",
    "\n",
    "print(\"개 : \", val_dogs_dir)\n",
    "print(\"고양이 : \", val_cats_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "# Step 1 - Convolution\n",
    "# Step 2 - Pooling\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "#   컨볼루션 3x3  32필터, 입력이미지 64x64x3\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "#   Pooling 필터 2x2, MaxPooling2D\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# 두번째 Convolutional 계층 추가\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "model.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))  # 개고양이 분류\n",
    "\n",
    "# Compiling the CNN\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ImageDataGenerator를 통한 학습용, 평가용 데이터 셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* rescale : 기본값 없음. 다른 변환을 제공된 값으로 데이터를 곱함.\n",
    "* zoom_range : 부동 소수점.[하한, 상한] 무작위 줌의 범위 [1-zoom_range, 1+zoom_range]\n",
    "* horizontal_flip : 인풋을 무작위로 가로로 뒤집기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale= 1./255,  # 크기 재조절.\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 가져오기\n",
    " * flow_from_directory 메소드를 사용하여 폴더 구조를 그대로 가져와, ImageDataGenerator 객체의 실제 데이터를 채워준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(train_dir,\n",
    "                                            target_size=(64,64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(val_dir,\n",
    "                                           target_size = (64,64),\n",
    "                                           batch_size = 32,\n",
    "                                           class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "300/300 [==============================] - 279s 929ms/step - loss: 0.6363 - accuracy: 0.6273 - val_loss: 0.5774 - val_accuracy: 0.6549 - loss: 0.7462 - accuracy: 0.48 - ETA: 1:01 - loss: \n",
      "Epoch 2/25\n",
      "300/300 [==============================] - 250s 833ms/step - loss: 0.5317 - accuracy: 0.7340 - val_loss: 0.8698 - val_accuracy: 0.7319\n",
      "Epoch 3/25\n",
      "300/300 [==============================] - 257s 856ms/step - loss: 0.4649 - accuracy: 0.7762 - val_loss: 0.5934 - val_accuracy: 0.71800.77 - ETA: 36s - loss: 0.4750 - accuracy: 0. - ETA: 36s - loss: 0.4734 - accuracy: 0.7 - ETA: 35s - loss: 0.4732 - accuracy: 0.77 - ETA: 35s - loss: 0.4729 - accuracy: 0 - ETA: 34s - loss: 0.4731 - accuracy: 0.7 - ETA: 33s - loss: 0.4733 - accu - ETA: 31s - loss: 0.4749  - ETA: 28s - loss: 0.4704 - ac - ETA: 26s - loss: 0.4725  - ETA: 22s - loss: 0.4737 - accuracy: 0.7 - ETA:\n",
      "Epoch 4/25\n",
      "300/300 [==============================] - 263s 877ms/step - loss: 0.4133 - accuracy: 0.8116 - val_loss: 1.3484 - val_accuracy: 0.7379\n",
      "Epoch 5/25\n",
      "300/300 [==============================] - 248s 828ms/step - loss: 0.3730 - accuracy: 0.8351 - val_loss: 0.6584 - val_accuracy: 0.7249. - ETA: 28s - loss: 0.3868 - accuracy: 0 - ETA: 28s - loss: 0.3854 - accuracy: 0. - ETA: 27s -\n",
      "Epoch 6/25\n",
      "300/300 [==============================] - 250s 834ms/step - loss: 0.3347 - accuracy: 0.8542 - val_loss: 0.1708 - val_accuracy: 0.7622 loss: 0.3486 - accuracy: 0 - ETA: 27s - loss: 0 - ETA: 23s - loss: 0.3421 - accuracy: 0.8 - ETA: 23s - loss: 0.3422 - accuracy: 0.8 - ETA: 22s - loss: 0.3400 - accuracy:  - ETA: 21s - loss: 0.3407 - accuracy: 0.851 - ETA: 21s - loss: 0.3411 - accuracy: 0. - ETA: 20s - loss: 0.3416 - accuracy: 0.85 - ETA: 20s - loss: 0.3415 - accuracy: 0. - ETA: 19s - loss: 0.3418 - accuracy: 0.85 - ETA: 19s - loss: 0.3417 - accuracy - ETA: 17s - loss: 0.\n",
      "Epoch 7/25\n",
      "300/300 [==============================] - 248s 827ms/step - loss: 0.2937 - accuracy: 0.8758 - val_loss: 0.7203 - val_accuracy: 0.7381\n",
      "Epoch 8/25\n",
      "300/300 [==============================] - 281s 935ms/step - loss: 0.2370 - accuracy: 0.9048 - val_loss: 0.2884 - val_accuracy: 0.7319\n",
      "Epoch 9/25\n",
      "300/300 [==============================] - 264s 879ms/step - loss: 0.1982 - accuracy: 0.9206 - val_loss: 1.1397 - val_accuracy: 0.7430loss: 0.2059 - acc - ETA: 20s - loss: 0.2026 - accuracy:  - ETA: 18s - los - ETA: 0s - loss: 0.1978 - accuracy: 0.\n",
      "Epoch 10/25\n",
      "300/300 [==============================] - 263s 876ms/step - loss: 0.1608 - accuracy: 0.9404 - val_loss: 0.7225 - val_accuracy: 0.7479\n",
      "Epoch 11/25\n",
      "300/300 [==============================] - 266s 887ms/step - loss: 0.1425 - accuracy: 0.9445 - val_loss: 0.6604 - val_accuracy: 0.7520 35s - loss: 0.1476 - accuracy: - ETA: 34s - loss: 0.1457 - accuracy - ETA: 33s - loss: 0.1458 - accuracy: 0.9 - ETA: 32s - loss: 0.1480 - accuracy: 0 - ETA: 32s - loss: 0.1497 - accurac - ETA: 30s - loss: 0.1506 - accuracy: 0.940 - ETA: 30s - loss: 0.1514 - accuracy: 0.9 - ETA: 29s - loss: 0.1521 -  - ETA: 27s - loss: 0.1507 - accuracy: 0.941 - ETA: 27s - loss: 0.1504 - accuracy:  - ETA: 26s - loss: 0.1508 - accurac - ETA: 24s - loss: 0.1508 - accuracy: 0.9 - ETA: 24s - loss: 0.1507 - accuracy: 0.9 - ETA: 23s - loss: 0.1494 - accuracy: 0.94 - ETA: 23s - loss: 0.1490 -  - ETA: 20s - loss: 0.1502 - accuracy: - ETA: 19s - loss: 0.1516 - accuracy: 0. - ETA: 18s - loss: 0.1525 - accuracy: 0.9 - ETA: 18s - loss: 0.1526 - accura - ETA: 16s - loss: 0.1518 - accuracy: 0.93 - ETA: 16s - loss: 0.1520 - accuracy: 0.9 - ETA: 15s - loss: 0.1516 -  - ETA: 12s - loss: 0.1500 - accuracy: 0.9 - ETA: 12s - loss: 0.1494 - accuracy: 0. - ETA: 11s - loss: 0. - ETA: 8s - loss: 0.1460 - accura - ETA: 7s - l - ETA: 5s - loss: 0.1434 - accuracy: 0. - ETA: 4s - loss: 0.1428 - accura - ETA: 3s - loss: 0.1425 - accuracy: 0.94 - ETA: 3s - loss: 0.1424 - accuracy: 0. - ETA: 3s - loss: 0.1423 -  - ETA: 1s - loss: 0.1422 - accura - ETA: 1s - loss: 0.1416 - accu\n",
      "Epoch 12/25\n",
      "300/300 [==============================] - 251s 838ms/step - loss: 0.1221 - accuracy: 0.9535 - val_loss: 1.8414 - val_accuracy: 0.7370\n",
      "Epoch 13/25\n",
      "300/300 [==============================] - 270s 901ms/step - loss: 0.1051 - accuracy: 0.9618 - val_loss: 0.8338 - val_accuracy: 0.7409\n",
      "Epoch 14/25\n",
      "300/300 [==============================] - 259s 862ms/step - loss: 0.0862 - accuracy: 0.9710 - val_loss: 0.3659 - val_accuracy: 0.7340 4 - ETA: 36s - loss: 0.0911 - ETA: 33s - loss: 0.08 - ETA: 30s - loss: 0.0896 - accuracy: 0 - ETA: 29s - loss: 0.0883 - acc - ETA: 26s - loss: 0.0887 - accuracy - ETA: 25s - loss: 0 - ETA: 20s - loss: 0.0910 - accuracy: 0.968 - ETA: 20s - loss: 0.0911 - a - ETA: 17s - loss: 0.0884 - accuracy: 0.969 - ETA: 17s - loss: 0.0883 - accuracy: 0.96 - ETA: 17s - loss: 0.0879 - accuracy: 0.969 - ETA: 17s - loss: 0.0877 - accuracy: - ETA: 15s - loss: 0.0870 - accuracy: 0.970 - ETA: 15s - loss: 0.0871 - a - ETA: 12s - loss: 0.0862 - accur - ETA: 10s - loss: 0.0862 - accuracy: 0.970 - ETA: 10s - loss: - ETA: 7s - loss: 0.086 - ETA: 6s - loss: 0.0869 - accuracy: 0. - ETA: 1s - loss: 0.0867 - accuracy:  - ETA: 1s - loss: 0.0862 - accuracy:  - ETA: 0s - loss: 0.0860 - accuracy: \n",
      "Epoch 15/25\n",
      "300/300 [==============================] - 262s 874ms/step - loss: 0.0682 - accuracy: 0.9762 - val_loss: 1.5180 - val_accuracy: 0.7390\n",
      "Epoch 16/25\n",
      "300/300 [==============================] - 334s 1s/step - loss: 0.0684 - accuracy: 0.9748 - val_loss: 2.8804 - val_accuracy: 0.7311 - ETA: 28s - loss: 0.0625 - accuracy:  - ETA: 26s - loss: 0.0620 - accuracy: 0.976 - ETA: 26s - loss: 0.0633 - accuracy: 0.97 - ETA: 25s - loss: 0.0634 - acc - ETA: 21s - loss: 0.0630 - accuracy: 0 - ETA: 20s - loss: 0.0644 - accuracy: - ETA: 18s - loss: 0.0647 - accuracy: 0.97 - ETA: 18s - loss: 0.0645 - accuracy: 0. - ETA: 17s - loss: 0.0642 - accuracy: 0 - ETA: 15s - loss: 0.0641 - accuracy: 0.975 - ETA: 15s - loss: 0.0647 - accura - ETA: 13s - loss: 0.0649 - accuracy: - ETA: 11s - loss: 0.0649 - accuracy:  - ETA: 10s - loss: 0.0660 - accuracy: - ETA: 9s - loss: 0.0665 - ac - ETA: 7s - loss: 0.0669 - accuracy: 0. - ETA: 7s - loss: 0 - ETA\n",
      "Epoch 17/25\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.0617 - accuracy: 0.9796"
     ]
    }
   ],
   "source": [
    "model.fit_generator(training_set,\n",
    "                   steps_per_epoch = 300,\n",
    "                   epochs=25,\n",
    "                   validation_data = test_set,\n",
    "                   validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 배치 단위로 생성한 데이터에 대해 모델을 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict_generator(test_set, steps=5)\n",
    "print(test_set.class_indices)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
