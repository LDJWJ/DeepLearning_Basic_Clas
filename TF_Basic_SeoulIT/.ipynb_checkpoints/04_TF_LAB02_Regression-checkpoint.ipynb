{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cVhtFALQK6wr"
   },
   "source": [
    "### 선형 회귀(Linear Regression) 모델 구현하기\n",
    "* 플레이스 홀더를 선언 후, 그래프 실행시에 데이터를 입력받아, 연산 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_0xoN3sSMcKK"
   },
   "source": [
    "### 2-1. 라이브러리 불러오기 및 데이터 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../img/TF_Regression01.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9979ab126f99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../img/TF_Regression01.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[1;32m-> 1197\u001b[1;33m                 metadata=metadata)\n\u001b[0m\u001b[0;32m   1198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'width'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1226\u001b[0m         \u001b[1;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1228\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1229\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1230\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../img/TF_Regression01.png'"
     ]
    }
   ],
   "source": [
    "display(Image(filename='../img/TF_Regression01.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oe3jSvHHL6qa"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습을 위한 데이터 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KgXrfJB9LoiK"
   },
   "outputs": [],
   "source": [
    "x_data = [1,2,3,4,5]\n",
    "y_data = [10,20,30,40,50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mkTwoRrIMOaK"
   },
   "source": [
    "### 2.2 W와 b를 각각 -1~1 사이의 균등분포(uniform distributiion)를 가진 무작위값으로 초기화수행\n",
    "* 가중치(Weight)와 Bias를 임의의 값(-1 ~ 1)으로 초기화\n",
    "* tf.random_uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None, name=None) : 균등 분포로 부터 난수값 발생."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 609,
     "status": "ok",
     "timestamp": 1547533637330,
     "user": {
      "displayName": "K Joy",
      "photoUrl": "",
      "userId": "10088839989700781050"
     },
     "user_tz": -540
    },
    "id": "DMssmk2tLrkK",
    "outputId": "a9276513-231f-417c-edb6-253e59d64df3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_1:0' shape=(1,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_uniform( [1], -1.0, 1.0) )\n",
    "b = tf.Variable(tf.random_uniform( [1], -1.0, 1.0) )\n",
    "print(W)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HPWL_aydL2X6"
   },
   "source": [
    "### 2.3 플레이스 홀더(placeholder) 설정(이름 지정 - name)\n",
    "* 플레이스 홀더는 나중에 데이터를 할당되는 심플한 변수이다.\n",
    "* 데이터 없이도 텐서 그래프의 작성이 가능하다.\n",
    "* feed_dict에 의해 나중에 값을 정의할 수 있다.\n",
    "* 배열, matrix, 몇몇의 숫자 등의 다양한 형태의 값을 가질 수 있다.\n",
    "* None은 임의의 행의 데이터를 가르킨다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 711,
     "status": "ok",
     "timestamp": 1547533806164,
     "user": {
      "displayName": "K Joy",
      "photoUrl": "",
      "userId": "10088839989700781050"
     },
     "user_tz": -540
    },
    "id": "ANfym_UBM7Bq",
    "outputId": "34ad17cd-f6af-4b1f-c873-788b3aff372a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "T = tf.placeholder(tf.float32)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 568,
     "status": "ok",
     "timestamp": 1547533777276,
     "user": {
      "displayName": "K Joy",
      "photoUrl": "",
      "userId": "10088839989700781050"
     },
     "user_tz": -540
    },
    "id": "AUOnOc5bMv1C",
    "outputId": "81c8578b-5639-4528-dc9f-6c24106d3a02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X:0\", dtype=float32)\n",
      "Tensor(\"Y:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, name='X')\n",
    "Y = tf.placeholder(tf.float32, name='Y')\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4 선형관계 수식 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형관계의 수식을 작성.\n",
    "# W : 가중치(Weight), b : 편향(bias)\n",
    "hypothesis = W * X + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTmsNk9rM3b6"
   },
   "outputs": [],
   "source": [
    "# hypothesis = W * X + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5SgrzGcmOL9L"
   },
   "source": [
    "### 2-5 손실함수(loss function)\n",
    " * 우리는 나중에 학습시에 Loss를 최소화하는 W와 b의 값을 구하게 된다.\n",
    " * 데이터에 대한 손실값을 계산하는 함수\n",
    " * 손실값이란 실제값과 모델이 예측한 값이 얼마나 차이가 나는가를 나타내는 값.\n",
    " * 손실값이 적을 수록 모델이 주어진 X값에 대한 Y값을 정확하게 예측할 수 있다라는 의미\n",
    " * 손실을 전체 데이터에 대해 구한 경우 이를 비용(cost)이라 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename='../img/TF_Regression02.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 704,
     "status": "ok",
     "timestamp": 1547534333613,
     "user": {
      "displayName": "K Joy",
      "photoUrl": "",
      "userId": "10088839989700781050"
     },
     "user_tz": -540
    },
    "id": "7nebYtivOTVy",
    "outputId": "33cd7f21-e350-4bbe-be6c-c87e6891a3b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hypothesis(예측) - Y(실제)\n",
    "# tf.square(예측과실제의차이) -> 제곱\n",
    "# tf.reduce_mean(a) -> a의 평균\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZH9zg79RO-Zz"
   },
   "source": [
    "### 2-6 최적화 함수(경사하강법)\n",
    " * **경사하강법** : 함수의 기울기를 구하고, 기울기가 낮은 쪽으로 계속 이동시키면서 최적의 값을 찾아 나간다.(즉 손실값을 낮춰가며, 계속 최적의 값을 찾아간다.)\n",
    " * 경사하강법(gradient descent)는 최적화 방법 중 가장 기본적인 알고리즘이다.\n",
    " * 최적화 함수란 가중치(w)와 편향(b)을 변경해 가면서 손실값을 최소화시키는 가장 최적화된 가중치와 편향값을 찾아주는 함수.\n",
    " * learning_rate는 학습을 얼마나 급하게 할 것인가를 설정하는 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 748,
     "status": "ok",
     "timestamp": 1547534427392,
     "user": {
      "displayName": "K Joy",
      "photoUrl": "",
      "userId": "10088839989700781050"
     },
     "user_tz": -540
    },
    "id": "3pJyX8ZjPJqL",
    "outputId": "5b8a893e-b1a4-432e-fc4d-c586702cce1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'GradientDescent' type=NoOp>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)\n",
    "train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n0Pgc9X-PWG7"
   },
   "source": [
    "* 학습을 진행하는 과정 중에 영향을 주는 변수를 **하이퍼파라미터(hyperparameter)**라 한다.  이에 따라 학습속도와 신경망 성능이 달라질 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "shXkFD9nQVBj"
   },
   "source": [
    "#### with를 이용하여 세션 블록(세션영역)을 생성\n",
    "* 출력 순서\n",
    "* step : 단계\n",
    "* cost_val : cost 비용\n",
    "* sess.run(W) : 가중치 값\n",
    "* sess.run(b) : 편향 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1767
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 594,
     "status": "ok",
     "timestamp": 1547535426517,
     "user": {
      "displayName": "K Joy",
      "photoUrl": "",
      "userId": "10088839989700781050"
     },
     "user_tz": -540
    },
    "id": "t19kelTPP91b",
    "outputId": "8f3291e7-3a3d-4a60-adb4-9f8d8f27cab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost = 902.91150  W =   2.940187 B =   0.518187 \n",
      "1 Cost = 526.56921  W =   4.462255 B =   0.931412 \n",
      "2 Cost = 307.25284  W =   5.624674 B =   1.245048 \n",
      "3 Cost = 179.44341  W =   6.512543 B =   1.482667 \n",
      "4 Cost = 104.95979  W =   7.190824 B =   1.662261 \n",
      "5 Cost = 61.55181   W =   7.709107 B =   1.797566 \n",
      "6 Cost = 36.25315   W =   8.105249 B =   1.899069 \n",
      "7 Cost = 21.50779   W =   8.408151 B =   1.974772 \n",
      "8 Cost = 12.91231   W =   8.639872 B =   2.030788 \n",
      "9 Cost = 7.90075    W =   8.817252 B =   2.071780 \n",
      "10 Cost = 4.97773    W =   8.953150 B =   2.101309 \n",
      "11 Cost = 3.27181    W =   9.057378 B =   2.122094 \n",
      "12 Cost = 2.27519    W =   9.137429 B =   2.136209 \n",
      "13 Cost = 1.69191    W =   9.199022 B =   2.145240 \n",
      "14 Cost = 1.34954    W =   9.246523 B =   2.150393 \n",
      "15 Cost = 1.14756    W =   9.283264 B =   2.152594 \n",
      "16 Cost = 1.02743    W =   9.311790 B =   2.152547 \n",
      "17 Cost = 0.95499    W =   9.334044 B =   2.150788 \n",
      "18 Cost = 0.91038    W =   9.351506 B =   2.147730 \n",
      "19 Cost = 0.88199    W =   9.365311 B =   2.143685 \n",
      "20 Cost = 0.86308    W =   9.376321 B =   2.138893 \n",
      "21 Cost = 0.84970    W =   9.385197 B =   2.133536 \n",
      "22 Cost = 0.83956    W =   9.392441 B =   2.127753 \n",
      "23 Cost = 0.83133    W =   9.398438 B =   2.121651 \n",
      "24 Cost = 0.82422    W =   9.403483 B =   2.115312 \n",
      "25 Cost = 0.81779    W =   9.407799 B =   2.108797 \n",
      "26 Cost = 0.81176    W =   9.411555 B =   2.102153 \n",
      "27 Cost = 0.80598    W =   9.414884 B =   2.095417 \n",
      "28 Cost = 0.80037    W =   9.417884 B =   2.088615 \n",
      "29 Cost = 0.79486    W =   9.420632 B =   2.081770 \n",
      "30 Cost = 0.78944    W =   9.423187 B =   2.074897 \n",
      "31 Cost = 0.78408    W =   9.425592 B =   2.068008 \n",
      "32 Cost = 0.77877    W =   9.427881 B =   2.061112 \n",
      "33 Cost = 0.77350    W =   9.430080 B =   2.054217 \n",
      "34 Cost = 0.76827    W =   9.432210 B =   2.047328 \n",
      "35 Cost = 0.76308    W =   9.434284 B =   2.040449 \n",
      "36 Cost = 0.75793    W =   9.436315 B =   2.033583 \n",
      "37 Cost = 0.75281    W =   9.438311 B =   2.026732 \n",
      "38 Cost = 0.74772    W =   9.440278 B =   2.019899 \n",
      "39 Cost = 0.74268    W =   9.442223 B =   2.013084 \n",
      "40 Cost = 0.73766    W =   9.444149 B =   2.006289 \n",
      "41 Cost = 0.73268    W =   9.446059 B =   1.999514 \n",
      "42 Cost = 0.72774    W =   9.447955 B =   1.992761 \n",
      "43 Cost = 0.72282    W =   9.449840 B =   1.986028 \n",
      "44 Cost = 0.71794    W =   9.451714 B =   1.979317 \n",
      "45 Cost = 0.71310    W =   9.453578 B =   1.972628 \n",
      "46 Cost = 0.70828    W =   9.455433 B =   1.965961 \n",
      "47 Cost = 0.70350    W =   9.457280 B =   1.959316 \n",
      "48 Cost = 0.69875    W =   9.459120 B =   1.952693 \n",
      "49 Cost = 0.69404    W =   9.460952 B =   1.946091 \n",
      "50 Cost = 0.68935    W =   9.462777 B =   1.939512 \n",
      "51 Cost = 0.68470    W =   9.464596 B =   1.932956 \n",
      "52 Cost = 0.68008    W =   9.466408 B =   1.926421 \n",
      "53 Cost = 0.67548    W =   9.468213 B =   1.919908 \n",
      "54 Cost = 0.67093    W =   9.470012 B =   1.913417 \n",
      "55 Cost = 0.66640    W =   9.471804 B =   1.906948 \n",
      "56 Cost = 0.66190    W =   9.473590 B =   1.900501 \n",
      "57 Cost = 0.65743    W =   9.475370 B =   1.894075 \n",
      "58 Cost = 0.65299    W =   9.477144 B =   1.887672 \n",
      "59 Cost = 0.64858    W =   9.478912 B =   1.881290 \n",
      "60 Cost = 0.64421    W =   9.480674 B =   1.874929 \n",
      "61 Cost = 0.63986    W =   9.482430 B =   1.868590 \n",
      "62 Cost = 0.63554    W =   9.484179 B =   1.862273 \n",
      "63 Cost = 0.63125    W =   9.485924 B =   1.855976 \n",
      "64 Cost = 0.62699    W =   9.487662 B =   1.849701 \n",
      "65 Cost = 0.62275    W =   9.489394 B =   1.843448 \n",
      "66 Cost = 0.61855    W =   9.491120 B =   1.837215 \n",
      "67 Cost = 0.61437    W =   9.492841 B =   1.831003 \n",
      "68 Cost = 0.61023    W =   9.494555 B =   1.824813 \n",
      "69 Cost = 0.60611    W =   9.496264 B =   1.818643 \n",
      "70 Cost = 0.60202    W =   9.497968 B =   1.812495 \n",
      "71 Cost = 0.59795    W =   9.499665 B =   1.806367 \n",
      "72 Cost = 0.59392    W =   9.501357 B =   1.800259 \n",
      "73 Cost = 0.58991    W =   9.503043 B =   1.794173 \n",
      "74 Cost = 0.58592    W =   9.504724 B =   1.788107 \n",
      "75 Cost = 0.58197    W =   9.506398 B =   1.782061 \n",
      "76 Cost = 0.57804    W =   9.508067 B =   1.776036 \n",
      "77 Cost = 0.57414    W =   9.509730 B =   1.770031 \n",
      "78 Cost = 0.57026    W =   9.511388 B =   1.764047 \n",
      "79 Cost = 0.56641    W =   9.513040 B =   1.758083 \n",
      "80 Cost = 0.56259    W =   9.514686 B =   1.752139 \n",
      "81 Cost = 0.55879    W =   9.516326 B =   1.746215 \n",
      "82 Cost = 0.55502    W =   9.517962 B =   1.740311 \n",
      "83 Cost = 0.55127    W =   9.519591 B =   1.734427 \n",
      "84 Cost = 0.54755    W =   9.521215 B =   1.728563 \n",
      "85 Cost = 0.54386    W =   9.522834 B =   1.722719 \n",
      "86 Cost = 0.54018    W =   9.524447 B =   1.716895 \n",
      "87 Cost = 0.53654    W =   9.526055 B =   1.711090 \n",
      "88 Cost = 0.53292    W =   9.527658 B =   1.705305 \n",
      "89 Cost = 0.52932    W =   9.529255 B =   1.699539 \n",
      "90 Cost = 0.52575    W =   9.530847 B =   1.693793 \n",
      "91 Cost = 0.52220    W =   9.532433 B =   1.688066 \n",
      "92 Cost = 0.51867    W =   9.534014 B =   1.682359 \n",
      "93 Cost = 0.51517    W =   9.535589 B =   1.676671 \n",
      "94 Cost = 0.51169    W =   9.537159 B =   1.671002 \n",
      "95 Cost = 0.50824    W =   9.538724 B =   1.665353 \n",
      "96 Cost = 0.50481    W =   9.540283 B =   1.659722 \n",
      "97 Cost = 0.50140    W =   9.541838 B =   1.654111 \n",
      "98 Cost = 0.49801    W =   9.543386 B =   1.648518 \n",
      "99 Cost = 0.49465    W =   9.544930 B =   1.642945 \n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "  for step in range(100):\n",
    "    _, cost_val = sess.run([train_op, cost], feed_dict={X:x_data, Y:y_data})\n",
    "    print(step, \"Cost = %-10.5f\" % cost_val, \"W = %10.6f\" % sess.run(W), \"B = %10.6f \" % sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생각해 보기\n",
    " * 만약 for문을 계속 반복시켜가면 W의 값은 어떤 값에 가까워질까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-iJDogycQSWb"
   },
   "source": [
    "### 2-7 학습 후, 결과값 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 570,
     "status": "ok",
     "timestamp": 1547535473738,
     "user": {
      "displayName": "K Joy",
      "photoUrl": "",
      "userId": "10088839989700781050"
     },
     "user_tz": -540
    },
    "id": "VDLCK7T7S0Gc",
    "outputId": "e56e868c-1cba-4dae-e565-f615eb6145bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1086.6752 [2.071835] [1.2386663]\n",
      "10 6.642415 [8.672422] [2.95255]\n",
      "20 1.6505979 [9.142491] [2.9721873]\n",
      "30 1.5219158 [9.199667] [2.8811414]\n",
      "40 1.4221544 [9.228242] [2.785733]\n",
      "50 1.3290131 [9.25407] [2.6930044]\n",
      "60 1.2419746 [9.278919] [2.60333]\n",
      "70 1.1606374 [9.302931] [2.5166397]\n",
      "80 1.0846274 [9.326143] [2.4328358]\n",
      "90 1.0135926 [9.348583] [2.3518229]\n",
      "100 0.94721144 [9.3702755] [2.273507]\n",
      "110 0.8851782 [9.391245] [2.1978]\n",
      "120 0.8272082 [9.411516] [2.124614]\n",
      "130 0.773033 [9.431112] [2.0538647]\n",
      "140 0.722408 [9.450056] [1.9854717]\n",
      "150 0.6750964 [9.4683695] [1.9193556]\n",
      "160 0.63088334 [9.486073] [1.8554412]\n",
      "170 0.58956724 [9.503185] [1.7936556]\n",
      "180 0.5509545 [9.51973] [1.7339272]\n",
      "190 0.51487255 [9.535723] [1.6761878]\n",
      "200 0.4811532 [9.551183] [1.6203711]\n",
      "210 0.449642 [9.566129] [1.5664132]\n",
      "220 0.42019424 [9.580576] [1.514252]\n",
      "230 0.39267734 [9.5945425] [1.4638278]\n",
      "240 0.36695927 [9.608045] [1.4150825]\n",
      "250 0.342927 [9.621097] [1.3679605]\n",
      "260 0.32046962 [9.633714] [1.322408]\n",
      "270 0.2994816 [9.645912] [1.278372]\n",
      "280 0.27986807 [9.657703] [1.2358024]\n",
      "290 0.26153928 [9.6691] [1.1946505]\n",
      "300 0.24441063 [9.68012] [1.1548692]\n",
      "310 0.22840329 [9.690772] [1.116412]\n",
      "320 0.21344599 [9.701069] [1.0792357]\n",
      "330 0.19946674 [9.711023] [1.0432972]\n",
      "340 0.186404 [9.720646] [1.0085558]\n",
      "350 0.17419592 [9.729949] [0.9749713]\n",
      "360 0.16278772 [9.738941] [0.942505]\n",
      "370 0.15212646 [9.747635] [0.9111198]\n",
      "380 0.1421642 [9.75604] [0.8807793]\n",
      "390 0.13285354 [9.764163] [0.851449]\n",
      "400 0.12415235 [9.772016] [0.82309586]\n",
      "410 0.1160215 [9.779608] [0.79568684]\n",
      "420 0.10842296 [9.786946] [0.7691906]\n",
      "430 0.10132293 [9.794042] [0.74357677]\n",
      "440 0.09468719 [9.8008995] [0.7188157]\n",
      "450 0.088486016 [9.807529] [0.6948794]\n",
      "460 0.082690656 [9.813939] [0.67174]\n",
      "470 0.07727547 [9.820134] [0.6493712]\n",
      "480 0.07221475 [9.826124] [0.62774724]\n",
      "490 0.06748499 [9.831913] [0.6068438]\n",
      "500 0.06306571 [9.837511] [0.58663625]\n",
      "510 0.058935266 [9.842922] [0.56710154]\n",
      "520 0.055075932 [9.848153] [0.54821694]\n",
      "530 0.05146868 [9.8532095] [0.52996135]\n",
      "540 0.048097648 [9.858097] [0.51231366]\n",
      "550 0.04494812 [9.862823] [0.49525386]\n",
      "560 0.04200472 [9.867391] [0.47876215]\n",
      "570 0.039253477 [9.871807] [0.4628193]\n",
      "580 0.036682554 [9.876075] [0.44740757]\n",
      "590 0.034280576 [9.880202] [0.4325091]\n",
      "600 0.032035433 [9.8841915] [0.41810635]\n",
      "610 0.029937064 [9.888048] [0.40418342]\n",
      "620 0.027976658 [9.891776] [0.39072406]\n",
      "630 0.026144441 [9.895379] [0.37771294]\n",
      "640 0.024432128 [9.898863] [0.36513537]\n",
      "650 0.02283186 [9.902231] [0.3529765]\n",
      "660 0.021336742 [9.905486] [0.34122244]\n",
      "670 0.019939441 [9.908633] [0.32986006]\n",
      "680 0.018633626 [9.911675] [0.318876]\n",
      "690 0.017413262 [9.914618] [0.30825803]\n",
      "700 0.016272843 [9.917461] [0.29799286]\n",
      "710 0.015207246 [9.92021] [0.28806934]\n",
      "720 0.014211165 [9.922866] [0.27847645]\n",
      "730 0.01328061 [9.925436] [0.26920277]\n",
      "740 0.012410845 [9.927918] [0.26023796]\n",
      "750 0.011597814 [9.930319] [0.2515721]\n",
      "760 0.010838385 [9.932639] [0.24319468]\n",
      "770 0.010128502 [9.934882] [0.23509626]\n",
      "780 0.0094652595 [9.937051] [0.2272675]\n",
      "790 0.008845331 [9.939147] [0.21969958]\n",
      "800 0.008265979 [9.941174] [0.21238348]\n",
      "810 0.007724566 [9.943131] [0.20531133]\n",
      "820 0.0072188824 [9.945026] [0.19847451]\n",
      "830 0.0067459694 [9.9468565] [0.1918652]\n",
      "840 0.0063042804 [9.948626] [0.18547635]\n",
      "850 0.00589136 [9.950336] [0.17930016]\n",
      "860 0.0055055916 [9.95199] [0.17332971]\n",
      "870 0.0051450925 [9.953589] [0.16755785]\n",
      "880 0.0048079635 [9.955134] [0.16197844]\n",
      "890 0.004493151 [9.956628] [0.15658474]\n",
      "900 0.004198831 [9.958073] [0.15137067]\n",
      "910 0.0039238627 [9.95947] [0.14632976]\n",
      "920 0.0036669355 [9.960819] [0.14145647]\n",
      "930 0.003426733 [9.962124] [0.13674591]\n",
      "940 0.003202341 [9.963385] [0.1321924]\n",
      "950 0.002992602 [9.964604] [0.1277904]\n",
      "960 0.0027965964 [9.965783] [0.12353506]\n",
      "970 0.0026134383 [9.966923] [0.11942142]\n",
      "980 0.00244234 [9.968024] [0.11544455]\n",
      "990 0.0022823347 [9.969089] [0.11160012]\n",
      "1000 0.00213288 [9.970118] [0.10788385]\n",
      "\n",
      "최종 학습된 결과로 예측해 보기\n",
      "Y = [9.970118] * X + [0.10788385] \n",
      "X:5, Y: [49.95847]\n",
      "X:2.5, Y: [25.033176]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  \n",
    "  for step in range(1001):\n",
    "    _, cost_val = sess.run([train_op, cost], feed_dict={X:x_data, Y:y_data})\n",
    "    if step%10==0:\n",
    "      print(step, cost_val, sess.run(W), sess.run(b))\n",
    "  \n",
    "  print()\n",
    "  print(\"최종 학습된 결과로 예측해 보기\")\n",
    "  print(\"Y = {Weight} * X + {Bias} \".format(Weight=sess.run(W), Bias=sess.run(b)))\n",
    "  print(\"X:5, Y:\", sess.run(hypothesis, feed_dict={X:5}))\n",
    "  print(\"X:2.5, Y:\", sess.run(hypothesis, feed_dict={X:2.5}))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TF_LAB02_Regression.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
