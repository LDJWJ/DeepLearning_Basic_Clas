{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역사\n",
    "* Hubel & Wiesel 연구 : 특정 뉴런은 특정 이미지 패턴에 반응한다.\n",
    "* 1959, 1962, 1968\n",
    "* 1980 - Neurocognitron \n",
    "* 1998 - 실용화 (우편번호 분류) 기계가 우편번호 분류를 해 주었다.(LeCun, Bottou 등)\n",
    "* 2012 - 비약적 발전(AlexNet)-Krizhevsky. 1998년에 비해 구조는 큰 차이가 없다.\n",
    "  * 이후에 모든 분야에 활용이 되기 시작함.\n",
    "* 물체 찾아내기 등\n",
    "* 자율주행차, 얼굴 인식, 비디오 분류, 자세를 평가, 암을 잡아내기, 한자 분류, 멸종위기 고래 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 합성곱층(convolutional layer)\n",
    "* 의미 : 필터를 이미지 위에서 컨볼루션시킨다.\n",
    "* 필터를 이미지 위에서 * 프로덕트 해 나간다.\n",
    "* filter의 depth는 같다\n",
    "  * 32 X 32 X 3 image <-> 5x5x3 filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하나의 필터는 하나의 맵(activation maps를 생성)\n",
    "<img src='../img/cs231n_cnn01.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여섯개의 필터를 가진다면 여섯개의 맵(activation maps를 생성)\n",
    "<img src='../img/cs231n_cnn02.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 위의 결과물 28 x 28 x 6의 맵이 다음으로 전달"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단계별 Conv 첫번째 6개의 필터,두번째 10개의 필터\n",
    "#### 여기서 주의 필터의 깊이는 앞의 결과물의 depth와 같아야 한다.\n",
    "<img src='../img/cs231n_cnn03.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 필터의 내용을 이미지화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 첫번째 합성곱층은 저수준 특성에 집중\n",
    "* 두번째 합성곱층은 첫번째 합성곱층의 픽셀에 집중\n",
    "* 이런 구조가 네트워크가 첫번째 은닉층에서는 저수준 특성에 집중하고, 그다음 은닉층에서는 고수준 특성으로 조합해 나가도록 돕는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/cs231n_cnn04.png'>\n",
    "* 첫번째 것은 앞의 원본 이미지의 픽셀에 대한 결과를 이미지화 시켰다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오렌지를 특징을 갖는 필터 15번째는 원본 이미지를 통해 해당 색을 횐색으로 표시함.\n",
    "<img src='../img/cs231n_cnn05.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../img/cs231n_cnn06.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 합성곱층의 뉴런\n",
    "* 다층 신경망은 한줄로 길게 늘어선 뉴런으로 구성\n",
    "* CNN에서는 각 층이 2D로 표현되므로 뉴런은 그와 상응하므로 연결이 쉽다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패딩\n",
    "* 높이와 너비를 이전층과 같게 하기 위해 입력의 주위에 0을 추가하는 것이 일반적이다. 이를 제로 패딩이라고 한다.\n",
    "* 필터의 크기에 따라 패딩의 크기를 다르게 해 준다.\n",
    "   * 필터 3x3 스트라이드 1 패딩 1\n",
    "   * 필터 5x5 스트라이드 1 패딩 2\n",
    "   * 필터 7x7 스트라이드 1 패딩 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 왜 패딩을 하는가?\n",
    "<img src='../img/cs231n_cnn07.png'>\n",
    "#### 거대한 신경망을 거치게 되면 패딩이 없을 경우, 사이즈가 계속 줄어든다. 이를 해결해 준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필터 또는 커널\n",
    "* 각각의 필터는 하나의 특성을 표현한다.\n",
    "* 만약 첫번째 필터가 가운데 열만 1로 채워져 있고, 나머지가 0인 7X7 행렬이라면, 이 뉴런은 수직선 부분을 제외하고\n",
    "필터 안에 있는 모든 것을 무시한다.\n",
    "* 만약 또 하나의 필터가 가로로 중앙 행만 1로 채워져 있고, 나머지가 0인 7X7 행렬이라면, 이 뉴런은 수평선 부분을 제외하고 필터 안에 있는 모든 것을 무시한다.\n",
    "* 필터를 이용하여 유사한 이미지 영역을 강조하는 **특성맵(feature map)**을 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 x 3 필터\n",
    "#### 5 x 5 필터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1x1 의 필터도 의미가 있는가?\n",
    "<img src='../img/cs231n_cnn08.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그렇다면 CNN의 차원은?\n",
    "* 합성곱층을 2D층으로 표현했지만, 실제로는 같은 크기의 여러개의 특성 맵으로 구성되어 있다. 3D로 표현이 더 정확."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파라미터\n",
    "* 하나의 feature map(특성맵)은 모든 뉴런이 같은 파라미터(가중치와 편향)을 공유\n",
    "* 다른 특성 맵은 다른 파라미터를 갖는다.\n",
    "\n",
    "#### 하나의 합성곱 층은 여러개의 필터를 동시에 적용하여 입력에 있는 여러 특성을 감지함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONV layer의 가지는 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하나. 하나의 activation map은 앞단의 작은 지역의 값과 연결되어 있다.\n",
    "#### 둘, 모든 가중치를 공유하고 있다. 하나의 필터의 결과물이기 때문에"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. 다른 활성맵은 가중치를 공유하지 않는다.\n",
    "### 02. 하나의 지역을 바라보고 있다.\n",
    "<img src='../img/cs231n_cnn09.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그렇다면 우리는 이미지를 작게 만들어 주어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pooling에 대해 알아보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. 특징을 더 작게 표시해 준다.\n",
    "### 02. 이미지를 다운 샘플링해 준다.\n",
    "<img src='../img/cs231n_cnn10.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. 역설적이지만 약간의 정보 손실을 통해 더 좋은 결과를 얻는다.\n",
    "<img src='../img/cs231n_cnn11.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected layer\n",
    "<img src='../img/cs231n_cnn06.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
