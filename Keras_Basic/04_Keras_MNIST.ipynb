{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST를 다층 퍼셉트론 신경망으로 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s 427us/step - loss: 2.2576 - acc: 0.1643 - val_loss: 2.2272 - val_acc: 0.1633\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 2.2072 - acc: 0.1657 - val_loss: 2.1908 - val_acc: 0.1800\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 2.1730 - acc: 0.1729 - val_loss: 2.1631 - val_acc: 0.1867\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 2.1441 - acc: 0.1786 - val_loss: 2.1372 - val_acc: 0.1867\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 2.1177 - acc: 0.1900 - val_loss: 2.1141 - val_acc: 0.1867\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 2.0940 - acc: 0.2029 - val_loss: 2.0931 - val_acc: 0.2033\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 2.0721 - acc: 0.2071 - val_loss: 2.0727 - val_acc: 0.2067\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 2.0520 - acc: 0.2129 - val_loss: 2.0564 - val_acc: 0.2067\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 2.0342 - acc: 0.2157 - val_loss: 2.0410 - val_acc: 0.2033\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 2.0190 - acc: 0.2143 - val_loss: 2.0269 - val_acc: 0.2067\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 2.0041 - acc: 0.2186 - val_loss: 2.0125 - val_acc: 0.2100\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.9911 - acc: 0.2200 - val_loss: 2.0037 - val_acc: 0.2100\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.9789 - acc: 0.2286 - val_loss: 1.9955 - val_acc: 0.2100\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.9685 - acc: 0.2329 - val_loss: 1.9833 - val_acc: 0.2067\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.9582 - acc: 0.2214 - val_loss: 1.9753 - val_acc: 0.2100\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.9484 - acc: 0.2357 - val_loss: 1.9686 - val_acc: 0.2000\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.9393 - acc: 0.2343 - val_loss: 1.9612 - val_acc: 0.2033\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.9309 - acc: 0.2314 - val_loss: 1.9537 - val_acc: 0.2100\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.9232 - acc: 0.2286 - val_loss: 1.9452 - val_acc: 0.2100\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.9156 - acc: 0.2386 - val_loss: 1.9392 - val_acc: 0.2100\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.9085 - acc: 0.2343 - val_loss: 1.9363 - val_acc: 0.2100\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.9011 - acc: 0.2386 - val_loss: 1.9289 - val_acc: 0.2033\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.8954 - acc: 0.2357 - val_loss: 1.9234 - val_acc: 0.2100\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.8895 - acc: 0.2314 - val_loss: 1.9201 - val_acc: 0.2067\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.8830 - acc: 0.2343 - val_loss: 1.9178 - val_acc: 0.2167\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.8769 - acc: 0.2300 - val_loss: 1.9105 - val_acc: 0.2167\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.8715 - acc: 0.2357 - val_loss: 1.9098 - val_acc: 0.2167\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.8662 - acc: 0.2400 - val_loss: 1.9094 - val_acc: 0.2000\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.8615 - acc: 0.2400 - val_loss: 1.9041 - val_acc: 0.1900\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.8565 - acc: 0.2243 - val_loss: 1.8976 - val_acc: 0.2167\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.8513 - acc: 0.2471 - val_loss: 1.8971 - val_acc: 0.1933\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.8463 - acc: 0.2371 - val_loss: 1.8925 - val_acc: 0.1900\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.8423 - acc: 0.2229 - val_loss: 1.8874 - val_acc: 0.2067\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.8382 - acc: 0.2371 - val_loss: 1.8808 - val_acc: 0.1933\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.8335 - acc: 0.2471 - val_loss: 1.8836 - val_acc: 0.1900\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.8299 - acc: 0.2343 - val_loss: 1.8756 - val_acc: 0.1967\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.8257 - acc: 0.2486 - val_loss: 1.8745 - val_acc: 0.1800\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.8220 - acc: 0.2371 - val_loss: 1.8700 - val_acc: 0.1933\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.8184 - acc: 0.2457 - val_loss: 1.8706 - val_acc: 0.1767\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.8144 - acc: 0.2314 - val_loss: 1.8677 - val_acc: 0.2000\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.8105 - acc: 0.2400 - val_loss: 1.8668 - val_acc: 0.1833\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.8075 - acc: 0.2471 - val_loss: 1.8635 - val_acc: 0.1800\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.8046 - acc: 0.2429 - val_loss: 1.8611 - val_acc: 0.1700\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.8001 - acc: 0.2371 - val_loss: 1.8566 - val_acc: 0.1967\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.7970 - acc: 0.2429 - val_loss: 1.8564 - val_acc: 0.1700\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.7939 - acc: 0.2271 - val_loss: 1.8528 - val_acc: 0.1933\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.7913 - acc: 0.2600 - val_loss: 1.8551 - val_acc: 0.1833\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.7886 - acc: 0.2471 - val_loss: 1.8543 - val_acc: 0.1867\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.7858 - acc: 0.2486 - val_loss: 1.8504 - val_acc: 0.1867\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.7819 - acc: 0.2471 - val_loss: 1.8443 - val_acc: 0.2267\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.7794 - acc: 0.2643 - val_loss: 1.8468 - val_acc: 0.1900\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.7762 - acc: 0.2486 - val_loss: 1.8411 - val_acc: 0.1933\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.7744 - acc: 0.2514 - val_loss: 1.8486 - val_acc: 0.2000\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.7716 - acc: 0.2700 - val_loss: 1.8472 - val_acc: 0.1800\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.7687 - acc: 0.2500 - val_loss: 1.8364 - val_acc: 0.2033\n",
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.7672 - acc: 0.2543 - val_loss: 1.8430 - val_acc: 0.2200\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.7641 - acc: 0.2714 - val_loss: 1.8390 - val_acc: 0.2167\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.7616 - acc: 0.2557 - val_loss: 1.8347 - val_acc: 0.2267\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.7590 - acc: 0.2671 - val_loss: 1.8329 - val_acc: 0.2233\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 136us/step - loss: 1.7552 - acc: 0.2614 - val_loss: 1.8256 - val_acc: 0.2500\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.7566 - acc: 0.2814 - val_loss: 1.8336 - val_acc: 0.2400\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.7531 - acc: 0.2729 - val_loss: 1.8312 - val_acc: 0.2267\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.7505 - acc: 0.2857 - val_loss: 1.8299 - val_acc: 0.2000\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.7484 - acc: 0.2800 - val_loss: 1.8268 - val_acc: 0.2200\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.7457 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2033\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.7439 - acc: 0.2786 - val_loss: 1.8296 - val_acc: 0.2067\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.7419 - acc: 0.2700 - val_loss: 1.8299 - val_acc: 0.2067\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.7405 - acc: 0.2729 - val_loss: 1.8238 - val_acc: 0.2000\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.7376 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2167\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.7356 - acc: 0.2857 - val_loss: 1.8269 - val_acc: 0.2433\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.7345 - acc: 0.2800 - val_loss: 1.8214 - val_acc: 0.2167\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.7328 - acc: 0.2857 - val_loss: 1.8226 - val_acc: 0.2133\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.7298 - acc: 0.2800 - val_loss: 1.8252 - val_acc: 0.2467\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.7283 - acc: 0.2857 - val_loss: 1.8257 - val_acc: 0.1967\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.7268 - acc: 0.2786 - val_loss: 1.8190 - val_acc: 0.2267\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.7255 - acc: 0.2857 - val_loss: 1.8196 - val_acc: 0.2233\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.7228 - acc: 0.3057 - val_loss: 1.8232 - val_acc: 0.2033\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.7212 - acc: 0.2857 - val_loss: 1.8187 - val_acc: 0.1933\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.7199 - acc: 0.2829 - val_loss: 1.8203 - val_acc: 0.2433\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.7188 - acc: 0.2929 - val_loss: 1.8197 - val_acc: 0.2067\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.7165 - acc: 0.2843 - val_loss: 1.8256 - val_acc: 0.2067\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.7142 - acc: 0.2829 - val_loss: 1.8144 - val_acc: 0.2667\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.7132 - acc: 0.2857 - val_loss: 1.8190 - val_acc: 0.2400\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.7127 - acc: 0.2986 - val_loss: 1.8220 - val_acc: 0.2167\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.7097 - acc: 0.2971 - val_loss: 1.8159 - val_acc: 0.2267\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.7082 - acc: 0.2800 - val_loss: 1.8136 - val_acc: 0.2633\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.7051 - acc: 0.3100 - val_loss: 1.8191 - val_acc: 0.2733\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.7062 - acc: 0.3043 - val_loss: 1.8125 - val_acc: 0.2433\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.7043 - acc: 0.3043 - val_loss: 1.8167 - val_acc: 0.2167\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.7027 - acc: 0.2843 - val_loss: 1.8151 - val_acc: 0.2233\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.7017 - acc: 0.3086 - val_loss: 1.8185 - val_acc: 0.2167\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.6987 - acc: 0.3129 - val_loss: 1.8215 - val_acc: 0.2067\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.6980 - acc: 0.3071 - val_loss: 1.8173 - val_acc: 0.2767\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.6970 - acc: 0.3157 - val_loss: 1.8176 - val_acc: 0.2100\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.6943 - acc: 0.2986 - val_loss: 1.8194 - val_acc: 0.2833\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.6948 - acc: 0.3014 - val_loss: 1.8095 - val_acc: 0.2233\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.6930 - acc: 0.3057 - val_loss: 1.8228 - val_acc: 0.2300\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6921 - acc: 0.3043 - val_loss: 1.8117 - val_acc: 0.2200\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6901 - acc: 0.3129 - val_loss: 1.8252 - val_acc: 0.2233\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.6890 - acc: 0.3129 - val_loss: 1.8210 - val_acc: 0.2267\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.6878 - acc: 0.3143 - val_loss: 1.8190 - val_acc: 0.2200\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.6877 - acc: 0.3014 - val_loss: 1.8219 - val_acc: 0.2300\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6843 - acc: 0.3000 - val_loss: 1.8102 - val_acc: 0.2500\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.6842 - acc: 0.3200 - val_loss: 1.8122 - val_acc: 0.2200\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.6821 - acc: 0.3071 - val_loss: 1.8063 - val_acc: 0.2067\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.6814 - acc: 0.3114 - val_loss: 1.8173 - val_acc: 0.2200\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.6805 - acc: 0.3071 - val_loss: 1.8228 - val_acc: 0.2367\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.6784 - acc: 0.3071 - val_loss: 1.8167 - val_acc: 0.2767\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.6782 - acc: 0.3143 - val_loss: 1.8178 - val_acc: 0.2300\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.6775 - acc: 0.3171 - val_loss: 1.8147 - val_acc: 0.2133\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.6775 - acc: 0.3043 - val_loss: 1.8173 - val_acc: 0.2233\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.6745 - acc: 0.3129 - val_loss: 1.8193 - val_acc: 0.2267\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6737 - acc: 0.3100 - val_loss: 1.8196 - val_acc: 0.2300\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.6724 - acc: 0.3014 - val_loss: 1.8221 - val_acc: 0.2300\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.6711 - acc: 0.3071 - val_loss: 1.8128 - val_acc: 0.2333\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.6703 - acc: 0.3157 - val_loss: 1.8255 - val_acc: 0.2300\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.6694 - acc: 0.3100 - val_loss: 1.8228 - val_acc: 0.2333\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.6682 - acc: 0.3114 - val_loss: 1.8262 - val_acc: 0.2333\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.6670 - acc: 0.3257 - val_loss: 1.8216 - val_acc: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.6661 - acc: 0.3114 - val_loss: 1.8219 - val_acc: 0.2200\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.6646 - acc: 0.3071 - val_loss: 1.8132 - val_acc: 0.2233\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.6637 - acc: 0.3229 - val_loss: 1.8194 - val_acc: 0.2200\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.6629 - acc: 0.3100 - val_loss: 1.8139 - val_acc: 0.2200\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.6619 - acc: 0.3143 - val_loss: 1.8187 - val_acc: 0.2267\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.6606 - acc: 0.3257 - val_loss: 1.8212 - val_acc: 0.2333\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.6592 - acc: 0.3143 - val_loss: 1.8245 - val_acc: 0.2233\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.6583 - acc: 0.3129 - val_loss: 1.8147 - val_acc: 0.2333\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.6565 - acc: 0.3300 - val_loss: 1.8280 - val_acc: 0.2300\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6570 - acc: 0.3143 - val_loss: 1.8193 - val_acc: 0.2200\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.6548 - acc: 0.3214 - val_loss: 1.8124 - val_acc: 0.2533\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.6547 - acc: 0.3229 - val_loss: 1.8202 - val_acc: 0.2500\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6545 - acc: 0.3200 - val_loss: 1.8133 - val_acc: 0.2267\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.6524 - acc: 0.3143 - val_loss: 1.8317 - val_acc: 0.2400\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.6514 - acc: 0.3214 - val_loss: 1.8226 - val_acc: 0.2733\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.6512 - acc: 0.3314 - val_loss: 1.8233 - val_acc: 0.2267\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.6493 - acc: 0.3186 - val_loss: 1.8168 - val_acc: 0.2200\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.6483 - acc: 0.3214 - val_loss: 1.8191 - val_acc: 0.2200\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.6488 - acc: 0.3257 - val_loss: 1.8199 - val_acc: 0.2167\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.6466 - acc: 0.3257 - val_loss: 1.8512 - val_acc: 0.2433\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6465 - acc: 0.3214 - val_loss: 1.8168 - val_acc: 0.2200\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.6446 - acc: 0.3229 - val_loss: 1.8284 - val_acc: 0.2267\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6437 - acc: 0.3243 - val_loss: 1.8154 - val_acc: 0.2633\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.6437 - acc: 0.3329 - val_loss: 1.8292 - val_acc: 0.2433\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.6431 - acc: 0.3329 - val_loss: 1.8273 - val_acc: 0.2300\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.6419 - acc: 0.3271 - val_loss: 1.8197 - val_acc: 0.2200\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.6392 - acc: 0.3343 - val_loss: 1.8324 - val_acc: 0.2233\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.6412 - acc: 0.3100 - val_loss: 1.8328 - val_acc: 0.2333\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.6390 - acc: 0.3243 - val_loss: 1.8306 - val_acc: 0.2500\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.6375 - acc: 0.3271 - val_loss: 1.8189 - val_acc: 0.2133\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.6367 - acc: 0.3229 - val_loss: 1.8276 - val_acc: 0.2233\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.6364 - acc: 0.3257 - val_loss: 1.8245 - val_acc: 0.2267\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.6350 - acc: 0.3214 - val_loss: 1.8290 - val_acc: 0.2233\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.6340 - acc: 0.3400 - val_loss: 1.8270 - val_acc: 0.2300\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.6319 - acc: 0.3457 - val_loss: 1.8343 - val_acc: 0.2233\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.6316 - acc: 0.3243 - val_loss: 1.8183 - val_acc: 0.2367\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.6326 - acc: 0.3329 - val_loss: 1.8309 - val_acc: 0.2200\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.6308 - acc: 0.3300 - val_loss: 1.8241 - val_acc: 0.2200\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.6308 - acc: 0.3343 - val_loss: 1.8329 - val_acc: 0.2300\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.6285 - acc: 0.3257 - val_loss: 1.8336 - val_acc: 0.2433\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.6278 - acc: 0.3300 - val_loss: 1.8304 - val_acc: 0.2233\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.6271 - acc: 0.3257 - val_loss: 1.8406 - val_acc: 0.2300\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.6265 - acc: 0.3271 - val_loss: 1.8350 - val_acc: 0.2267\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.6254 - acc: 0.3371 - val_loss: 1.8365 - val_acc: 0.2300\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.6239 - acc: 0.3314 - val_loss: 1.8264 - val_acc: 0.2100\n",
      "Epoch 165/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.6236 - acc: 0.3200 - val_loss: 1.8396 - val_acc: 0.2367\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.6230 - acc: 0.3286 - val_loss: 1.8344 - val_acc: 0.2233\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.6221 - acc: 0.3314 - val_loss: 1.8389 - val_acc: 0.2633\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.6208 - acc: 0.3386 - val_loss: 1.8444 - val_acc: 0.2200\n",
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.6198 - acc: 0.3386 - val_loss: 1.8525 - val_acc: 0.2233\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.6191 - acc: 0.3371 - val_loss: 1.8369 - val_acc: 0.2233\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.6170 - acc: 0.3271 - val_loss: 1.8517 - val_acc: 0.2600\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.6164 - acc: 0.3386 - val_loss: 1.8397 - val_acc: 0.2133\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.6182 - acc: 0.3386 - val_loss: 1.8392 - val_acc: 0.2367\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.6167 - acc: 0.3300 - val_loss: 1.8420 - val_acc: 0.2200\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.6166 - acc: 0.3357 - val_loss: 1.8406 - val_acc: 0.2200\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6143 - acc: 0.3229 - val_loss: 1.8437 - val_acc: 0.2600\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.6134 - acc: 0.3371 - val_loss: 1.8384 - val_acc: 0.2167\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.6139 - acc: 0.3371 - val_loss: 1.8446 - val_acc: 0.2267\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 131us/step - loss: 1.6134 - acc: 0.3400 - val_loss: 1.8376 - val_acc: 0.2233\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.6110 - acc: 0.3371 - val_loss: 1.8415 - val_acc: 0.2667\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.6115 - acc: 0.3457 - val_loss: 1.8339 - val_acc: 0.2567\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.6106 - acc: 0.3471 - val_loss: 1.8365 - val_acc: 0.2167\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.6115 - acc: 0.3300 - val_loss: 1.8411 - val_acc: 0.2333\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.6093 - acc: 0.3443 - val_loss: 1.8453 - val_acc: 0.2267\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.6076 - acc: 0.3386 - val_loss: 1.8641 - val_acc: 0.2200\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.6086 - acc: 0.3443 - val_loss: 1.8449 - val_acc: 0.2233\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.6065 - acc: 0.3543 - val_loss: 1.8442 - val_acc: 0.2167\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.6075 - acc: 0.3386 - val_loss: 1.8412 - val_acc: 0.2133\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.6045 - acc: 0.3529 - val_loss: 1.8517 - val_acc: 0.2233\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.6065 - acc: 0.3314 - val_loss: 1.8401 - val_acc: 0.2300\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.6042 - acc: 0.3529 - val_loss: 1.8564 - val_acc: 0.2233\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.6044 - acc: 0.3500 - val_loss: 1.8503 - val_acc: 0.2200\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.6029 - acc: 0.3357 - val_loss: 1.8539 - val_acc: 0.2267\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.6025 - acc: 0.3414 - val_loss: 1.8470 - val_acc: 0.2267\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.6019 - acc: 0.3457 - val_loss: 1.8453 - val_acc: 0.2467\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.6016 - acc: 0.3514 - val_loss: 1.8472 - val_acc: 0.2167\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.6002 - acc: 0.3443 - val_loss: 1.8488 - val_acc: 0.2300\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.6005 - acc: 0.3386 - val_loss: 1.8591 - val_acc: 0.2200\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.6003 - acc: 0.3429 - val_loss: 1.8558 - val_acc: 0.2200\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.5975 - acc: 0.3457 - val_loss: 1.8604 - val_acc: 0.2633\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.5986 - acc: 0.3457 - val_loss: 1.8469 - val_acc: 0.2167\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5979 - acc: 0.3414 - val_loss: 1.8478 - val_acc: 0.2100\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5965 - acc: 0.3343 - val_loss: 1.8562 - val_acc: 0.2267\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5953 - acc: 0.3557 - val_loss: 1.8461 - val_acc: 0.2067\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.5953 - acc: 0.3429 - val_loss: 1.8508 - val_acc: 0.2200\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.5946 - acc: 0.3500 - val_loss: 1.8463 - val_acc: 0.2133\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.5947 - acc: 0.3543 - val_loss: 1.8537 - val_acc: 0.2233\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.5920 - acc: 0.3414 - val_loss: 1.8557 - val_acc: 0.2233\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5919 - acc: 0.3514 - val_loss: 1.8521 - val_acc: 0.2300\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5915 - acc: 0.3443 - val_loss: 1.8523 - val_acc: 0.2267\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5903 - acc: 0.3371 - val_loss: 1.8456 - val_acc: 0.2567\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.5913 - acc: 0.3471 - val_loss: 1.8593 - val_acc: 0.2200\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5894 - acc: 0.3500 - val_loss: 1.8519 - val_acc: 0.2233\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5905 - acc: 0.3457 - val_loss: 1.8541 - val_acc: 0.2267\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.5886 - acc: 0.3514 - val_loss: 1.8602 - val_acc: 0.2667\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.5895 - acc: 0.3486 - val_loss: 1.8624 - val_acc: 0.2267\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.5881 - acc: 0.3471 - val_loss: 1.8638 - val_acc: 0.2300\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.5876 - acc: 0.3486 - val_loss: 1.8600 - val_acc: 0.2300\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5865 - acc: 0.3500 - val_loss: 1.8659 - val_acc: 0.2267\n",
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.5855 - acc: 0.3514 - val_loss: 1.8581 - val_acc: 0.2267\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5855 - acc: 0.3471 - val_loss: 1.8621 - val_acc: 0.2267\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5845 - acc: 0.3514 - val_loss: 1.8751 - val_acc: 0.2500\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5844 - acc: 0.3443 - val_loss: 1.8615 - val_acc: 0.2600\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5845 - acc: 0.3529 - val_loss: 1.8766 - val_acc: 0.2467\n",
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5833 - acc: 0.3457 - val_loss: 1.8572 - val_acc: 0.2167\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5835 - acc: 0.3486 - val_loss: 1.8686 - val_acc: 0.2233\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5825 - acc: 0.3486 - val_loss: 1.8611 - val_acc: 0.2133\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5825 - acc: 0.3443 - val_loss: 1.8693 - val_acc: 0.2267\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5801 - acc: 0.3471 - val_loss: 1.8688 - val_acc: 0.2233\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5818 - acc: 0.3471 - val_loss: 1.8635 - val_acc: 0.2133\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.5797 - acc: 0.3529 - val_loss: 1.8605 - val_acc: 0.2200\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.5809 - acc: 0.3514 - val_loss: 1.8730 - val_acc: 0.2133\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5796 - acc: 0.3486 - val_loss: 1.8781 - val_acc: 0.2200\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5791 - acc: 0.3457 - val_loss: 1.8666 - val_acc: 0.2133\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.5777 - acc: 0.3571 - val_loss: 1.8693 - val_acc: 0.2100\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.5778 - acc: 0.3443 - val_loss: 1.8664 - val_acc: 0.2133\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5770 - acc: 0.3429 - val_loss: 1.8718 - val_acc: 0.2300\n",
      "Epoch 238/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 142us/step - loss: 1.5774 - acc: 0.3471 - val_loss: 1.8613 - val_acc: 0.2200\n",
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5770 - acc: 0.3571 - val_loss: 1.8682 - val_acc: 0.2267\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.5749 - acc: 0.3571 - val_loss: 1.8719 - val_acc: 0.2500\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5749 - acc: 0.3571 - val_loss: 1.8738 - val_acc: 0.2433\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.5743 - acc: 0.3514 - val_loss: 1.8733 - val_acc: 0.2100\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.5743 - acc: 0.3629 - val_loss: 1.8806 - val_acc: 0.2200\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.5713 - acc: 0.3557 - val_loss: 1.8724 - val_acc: 0.2200\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5715 - acc: 0.3586 - val_loss: 1.8838 - val_acc: 0.2233\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5712 - acc: 0.3543 - val_loss: 1.8710 - val_acc: 0.2533\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.5722 - acc: 0.3557 - val_loss: 1.8631 - val_acc: 0.2167\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.5716 - acc: 0.3557 - val_loss: 1.8700 - val_acc: 0.2233\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.5712 - acc: 0.3471 - val_loss: 1.8840 - val_acc: 0.2233\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5680 - acc: 0.3657 - val_loss: 1.8981 - val_acc: 0.2167\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5704 - acc: 0.3486 - val_loss: 1.8793 - val_acc: 0.2400\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.5682 - acc: 0.3643 - val_loss: 1.8744 - val_acc: 0.2200\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5689 - acc: 0.3586 - val_loss: 1.8820 - val_acc: 0.2133\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5677 - acc: 0.3571 - val_loss: 1.8835 - val_acc: 0.2267\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.5681 - acc: 0.3457 - val_loss: 1.8713 - val_acc: 0.2267\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5657 - acc: 0.3571 - val_loss: 1.8761 - val_acc: 0.2533\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5667 - acc: 0.3514 - val_loss: 1.8912 - val_acc: 0.2467\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.5649 - acc: 0.3614 - val_loss: 1.8946 - val_acc: 0.2567\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5648 - acc: 0.3643 - val_loss: 1.8911 - val_acc: 0.2167\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.5657 - acc: 0.3600 - val_loss: 1.8989 - val_acc: 0.2200\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.5637 - acc: 0.3571 - val_loss: 1.8751 - val_acc: 0.2167\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.5638 - acc: 0.3614 - val_loss: 1.8836 - val_acc: 0.2100\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5631 - acc: 0.3629 - val_loss: 1.8858 - val_acc: 0.2100\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5640 - acc: 0.3571 - val_loss: 1.8812 - val_acc: 0.2133\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5638 - acc: 0.3686 - val_loss: 1.8902 - val_acc: 0.2200\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.5614 - acc: 0.3614 - val_loss: 1.8968 - val_acc: 0.2500\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5612 - acc: 0.3629 - val_loss: 1.8918 - val_acc: 0.2300\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5613 - acc: 0.3614 - val_loss: 1.8757 - val_acc: 0.2100\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.5601 - acc: 0.3643 - val_loss: 1.8854 - val_acc: 0.2133\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.5594 - acc: 0.3671 - val_loss: 1.8674 - val_acc: 0.2333\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5610 - acc: 0.3657 - val_loss: 1.8914 - val_acc: 0.2333\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.5595 - acc: 0.3600 - val_loss: 1.9030 - val_acc: 0.2267\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.5591 - acc: 0.3571 - val_loss: 1.8964 - val_acc: 0.2200\n",
      "Epoch 274/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5589 - acc: 0.3457 - val_loss: 1.8841 - val_acc: 0.2233\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.5589 - acc: 0.3629 - val_loss: 1.8914 - val_acc: 0.2200\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.5579 - acc: 0.3529 - val_loss: 1.8967 - val_acc: 0.2533\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5581 - acc: 0.3714 - val_loss: 1.8909 - val_acc: 0.2167\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5578 - acc: 0.3600 - val_loss: 1.9032 - val_acc: 0.2300\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.5559 - acc: 0.3571 - val_loss: 1.8859 - val_acc: 0.2167\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5559 - acc: 0.3700 - val_loss: 1.8876 - val_acc: 0.2167\n",
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5541 - acc: 0.3586 - val_loss: 1.8906 - val_acc: 0.2333\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.5553 - acc: 0.3671 - val_loss: 1.8840 - val_acc: 0.2133\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.5543 - acc: 0.3557 - val_loss: 1.8927 - val_acc: 0.2167\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.5542 - acc: 0.3614 - val_loss: 1.8936 - val_acc: 0.2567\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5535 - acc: 0.3557 - val_loss: 1.8887 - val_acc: 0.2200\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5536 - acc: 0.3586 - val_loss: 1.8989 - val_acc: 0.2233\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.5527 - acc: 0.3686 - val_loss: 1.9019 - val_acc: 0.2133\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5525 - acc: 0.3600 - val_loss: 1.8930 - val_acc: 0.2133\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5519 - acc: 0.3600 - val_loss: 1.9014 - val_acc: 0.2167\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5514 - acc: 0.3657 - val_loss: 1.9032 - val_acc: 0.2200\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.5513 - acc: 0.3586 - val_loss: 1.9037 - val_acc: 0.2167\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.5509 - acc: 0.3543 - val_loss: 1.8995 - val_acc: 0.2433\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.5507 - acc: 0.3543 - val_loss: 1.9011 - val_acc: 0.2300\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5497 - acc: 0.3543 - val_loss: 1.9002 - val_acc: 0.2567\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5499 - acc: 0.3657 - val_loss: 1.9120 - val_acc: 0.2200\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.5495 - acc: 0.3571 - val_loss: 1.9104 - val_acc: 0.2133\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 137us/step - loss: 1.5479 - acc: 0.3571 - val_loss: 1.9128 - val_acc: 0.2167\n",
      "Epoch 298/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5477 - acc: 0.3486 - val_loss: 1.8958 - val_acc: 0.2267\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.5485 - acc: 0.3686 - val_loss: 1.9145 - val_acc: 0.2267\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5472 - acc: 0.3629 - val_loss: 1.9031 - val_acc: 0.2300\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5469 - acc: 0.3629 - val_loss: 1.8934 - val_acc: 0.2200\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.5479 - acc: 0.3657 - val_loss: 1.9081 - val_acc: 0.2167\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5464 - acc: 0.3529 - val_loss: 1.9016 - val_acc: 0.2333\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5452 - acc: 0.3671 - val_loss: 1.9066 - val_acc: 0.2200\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5432 - acc: 0.3643 - val_loss: 1.9140 - val_acc: 0.2267\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.5458 - acc: 0.3600 - val_loss: 1.9100 - val_acc: 0.2233\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.5436 - acc: 0.3671 - val_loss: 1.9064 - val_acc: 0.2267\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.5453 - acc: 0.3600 - val_loss: 1.9129 - val_acc: 0.2333\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.5435 - acc: 0.3643 - val_loss: 1.9120 - val_acc: 0.2367\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.5448 - acc: 0.3671 - val_loss: 1.9110 - val_acc: 0.2167\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5426 - acc: 0.3586 - val_loss: 1.9058 - val_acc: 0.2300\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5423 - acc: 0.3729 - val_loss: 1.9273 - val_acc: 0.2367\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5387 - acc: 0.3657 - val_loss: 1.9056 - val_acc: 0.2633\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.5433 - acc: 0.3686 - val_loss: 1.9131 - val_acc: 0.2300\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5406 - acc: 0.3657 - val_loss: 1.9118 - val_acc: 0.2233\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.5404 - acc: 0.3614 - val_loss: 1.9141 - val_acc: 0.2233\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.5412 - acc: 0.3614 - val_loss: 1.9213 - val_acc: 0.2333\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5408 - acc: 0.3614 - val_loss: 1.9096 - val_acc: 0.2300\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5390 - acc: 0.3614 - val_loss: 1.9092 - val_acc: 0.2300\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5392 - acc: 0.3629 - val_loss: 1.9278 - val_acc: 0.2233\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.5392 - acc: 0.3686 - val_loss: 1.9258 - val_acc: 0.2300\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.5375 - acc: 0.3671 - val_loss: 1.9181 - val_acc: 0.2533\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.5383 - acc: 0.3714 - val_loss: 1.9197 - val_acc: 0.2300\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5373 - acc: 0.3657 - val_loss: 1.9227 - val_acc: 0.2200\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.5387 - acc: 0.3600 - val_loss: 1.9178 - val_acc: 0.2133\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.5365 - acc: 0.3614 - val_loss: 1.9227 - val_acc: 0.2200\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5359 - acc: 0.3743 - val_loss: 1.9378 - val_acc: 0.2333\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.5366 - acc: 0.3657 - val_loss: 1.9307 - val_acc: 0.2233\n",
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5354 - acc: 0.3714 - val_loss: 1.9147 - val_acc: 0.2300\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5351 - acc: 0.3600 - val_loss: 1.9222 - val_acc: 0.2333\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.5338 - acc: 0.3714 - val_loss: 1.9155 - val_acc: 0.2200\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5346 - acc: 0.3571 - val_loss: 1.9340 - val_acc: 0.2500\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.5358 - acc: 0.3671 - val_loss: 1.9234 - val_acc: 0.2233\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s 151us/step - loss: 1.5349 - acc: 0.3629 - val_loss: 1.9289 - val_acc: 0.2233\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.5327 - acc: 0.3757 - val_loss: 1.9246 - val_acc: 0.2567\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.5335 - acc: 0.3786 - val_loss: 1.9184 - val_acc: 0.2300\n",
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.5330 - acc: 0.3757 - val_loss: 1.9324 - val_acc: 0.2300\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.5320 - acc: 0.3743 - val_loss: 1.9238 - val_acc: 0.2133\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5314 - acc: 0.3700 - val_loss: 1.9157 - val_acc: 0.2167\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.5328 - acc: 0.3729 - val_loss: 1.9403 - val_acc: 0.2267\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.5317 - acc: 0.3757 - val_loss: 1.9258 - val_acc: 0.2267\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.5313 - acc: 0.3600 - val_loss: 1.9441 - val_acc: 0.2167\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.5310 - acc: 0.3686 - val_loss: 1.9333 - val_acc: 0.2267\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5308 - acc: 0.3671 - val_loss: 1.9431 - val_acc: 0.2300\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5291 - acc: 0.3686 - val_loss: 1.9443 - val_acc: 0.2567\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5301 - acc: 0.3700 - val_loss: 1.9314 - val_acc: 0.2267\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s 163us/step - loss: 1.5277 - acc: 0.3800 - val_loss: 1.9199 - val_acc: 0.2200\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.5284 - acc: 0.3643 - val_loss: 1.9294 - val_acc: 0.2167\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.5281 - acc: 0.3700 - val_loss: 1.9273 - val_acc: 0.2133\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.5282 - acc: 0.3657 - val_loss: 1.9311 - val_acc: 0.2300\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.5264 - acc: 0.3757 - val_loss: 1.9309 - val_acc: 0.2333\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.5283 - acc: 0.3729 - val_loss: 1.9282 - val_acc: 0.2300\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.5256 - acc: 0.3657 - val_loss: 1.9422 - val_acc: 0.2300\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.5279 - acc: 0.3700 - val_loss: 1.9350 - val_acc: 0.2167\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.5261 - acc: 0.3600 - val_loss: 1.9553 - val_acc: 0.2267\n",
      "Epoch 356/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 159us/step - loss: 1.5260 - acc: 0.3700 - val_loss: 1.9442 - val_acc: 0.2433\n",
      "Epoch 357/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.5259 - acc: 0.3743 - val_loss: 1.9355 - val_acc: 0.2267\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s 163us/step - loss: 1.5251 - acc: 0.3729 - val_loss: 1.9494 - val_acc: 0.2233\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.5251 - acc: 0.3729 - val_loss: 1.9450 - val_acc: 0.2133\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.5232 - acc: 0.3743 - val_loss: 1.9454 - val_acc: 0.2233\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.5232 - acc: 0.3686 - val_loss: 1.9485 - val_acc: 0.2300\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.5240 - acc: 0.3643 - val_loss: 1.9508 - val_acc: 0.2267\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.5215 - acc: 0.3757 - val_loss: 1.9527 - val_acc: 0.2333\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.5230 - acc: 0.3643 - val_loss: 1.9381 - val_acc: 0.2300\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.5224 - acc: 0.3771 - val_loss: 1.9524 - val_acc: 0.2267\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5222 - acc: 0.3686 - val_loss: 1.9406 - val_acc: 0.2133\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.5221 - acc: 0.3757 - val_loss: 1.9567 - val_acc: 0.2300\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.5206 - acc: 0.3786 - val_loss: 1.9551 - val_acc: 0.2367\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.5207 - acc: 0.3629 - val_loss: 1.9321 - val_acc: 0.2367\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.5200 - acc: 0.3757 - val_loss: 1.9534 - val_acc: 0.2400\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.5209 - acc: 0.3671 - val_loss: 1.9508 - val_acc: 0.2233\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.5195 - acc: 0.3729 - val_loss: 1.9590 - val_acc: 0.2333\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s 166us/step - loss: 1.5205 - acc: 0.3757 - val_loss: 1.9453 - val_acc: 0.2133\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s 161us/step - loss: 1.5197 - acc: 0.3686 - val_loss: 1.9514 - val_acc: 0.2267\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.5181 - acc: 0.3843 - val_loss: 1.9386 - val_acc: 0.2267\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.5182 - acc: 0.3800 - val_loss: 1.9488 - val_acc: 0.2167\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s 159us/step - loss: 1.5170 - acc: 0.3743 - val_loss: 1.9760 - val_acc: 0.2267\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.5182 - acc: 0.3743 - val_loss: 1.9761 - val_acc: 0.2367\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.5188 - acc: 0.3700 - val_loss: 1.9516 - val_acc: 0.2367\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.5166 - acc: 0.3671 - val_loss: 1.9602 - val_acc: 0.2567\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.5180 - acc: 0.3786 - val_loss: 1.9711 - val_acc: 0.2167\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.5161 - acc: 0.3743 - val_loss: 1.9585 - val_acc: 0.2267\n",
      "Epoch 383/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.5155 - acc: 0.3700 - val_loss: 1.9714 - val_acc: 0.2433\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.5164 - acc: 0.3771 - val_loss: 1.9509 - val_acc: 0.2233\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.5163 - acc: 0.3743 - val_loss: 1.9579 - val_acc: 0.2267\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.5156 - acc: 0.3714 - val_loss: 1.9502 - val_acc: 0.2333\n",
      "Epoch 387/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5153 - acc: 0.3743 - val_loss: 1.9578 - val_acc: 0.2300\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.5143 - acc: 0.3714 - val_loss: 1.9668 - val_acc: 0.2467\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.5158 - acc: 0.3800 - val_loss: 1.9490 - val_acc: 0.2267\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.5125 - acc: 0.3671 - val_loss: 1.9572 - val_acc: 0.2400\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.5132 - acc: 0.3757 - val_loss: 1.9539 - val_acc: 0.2367\n",
      "Epoch 392/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.5137 - acc: 0.3714 - val_loss: 1.9599 - val_acc: 0.2233\n",
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.5137 - acc: 0.3757 - val_loss: 1.9730 - val_acc: 0.2233\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.5136 - acc: 0.3757 - val_loss: 1.9565 - val_acc: 0.2267\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s 163us/step - loss: 1.5132 - acc: 0.3771 - val_loss: 1.9565 - val_acc: 0.2167\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.5124 - acc: 0.3771 - val_loss: 1.9619 - val_acc: 0.2167\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.5111 - acc: 0.3857 - val_loss: 1.9755 - val_acc: 0.2367\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.5124 - acc: 0.3643 - val_loss: 1.9588 - val_acc: 0.2200\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s 164us/step - loss: 1.5107 - acc: 0.3743 - val_loss: 1.9872 - val_acc: 0.2333\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 1.5113 - acc: 0.3643 - val_loss: 1.9599 - val_acc: 0.2167\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s 159us/step - loss: 1.5109 - acc: 0.3657 - val_loss: 1.9595 - val_acc: 0.2267\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.5086 - acc: 0.3771 - val_loss: 1.9650 - val_acc: 0.2233\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.5068 - acc: 0.3843 - val_loss: 1.9930 - val_acc: 0.2200\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.5085 - acc: 0.3743 - val_loss: 1.9678 - val_acc: 0.2333\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s 169us/step - loss: 1.5074 - acc: 0.3800 - val_loss: 1.9811 - val_acc: 0.2300\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s 167us/step - loss: 1.5085 - acc: 0.3771 - val_loss: 1.9745 - val_acc: 0.2200\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.5080 - acc: 0.3714 - val_loss: 1.9792 - val_acc: 0.2267\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.5077 - acc: 0.3757 - val_loss: 1.9706 - val_acc: 0.2267\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.5040 - acc: 0.3700 - val_loss: 1.9783 - val_acc: 0.2367\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s 156us/step - loss: 1.5058 - acc: 0.3771 - val_loss: 1.9611 - val_acc: 0.2267\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s 165us/step - loss: 1.5056 - acc: 0.3714 - val_loss: 1.9817 - val_acc: 0.2300\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s 158us/step - loss: 1.5048 - acc: 0.3843 - val_loss: 1.9719 - val_acc: 0.2233\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s 157us/step - loss: 1.5033 - acc: 0.3771 - val_loss: 1.9760 - val_acc: 0.2333\n",
      "Epoch 414/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.5043 - acc: 0.3786 - val_loss: 1.9842 - val_acc: 0.2333\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 135us/step - loss: 1.5015 - acc: 0.3786 - val_loss: 1.9778 - val_acc: 0.2333\n",
      "Epoch 416/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.5031 - acc: 0.3843 - val_loss: 1.9889 - val_acc: 0.2267\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s 162us/step - loss: 1.5032 - acc: 0.3786 - val_loss: 1.9804 - val_acc: 0.2200\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.5016 - acc: 0.3871 - val_loss: 1.9744 - val_acc: 0.2333\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.5019 - acc: 0.3786 - val_loss: 1.9663 - val_acc: 0.2200\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5015 - acc: 0.3800 - val_loss: 1.9877 - val_acc: 0.2300\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.5011 - acc: 0.3829 - val_loss: 1.9692 - val_acc: 0.2433\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.5004 - acc: 0.3743 - val_loss: 1.9747 - val_acc: 0.2433\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s 102us/step - loss: 1.5003 - acc: 0.3814 - val_loss: 1.9792 - val_acc: 0.2333\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.5001 - acc: 0.3757 - val_loss: 1.9678 - val_acc: 0.2200\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4991 - acc: 0.3886 - val_loss: 1.9619 - val_acc: 0.2400\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4984 - acc: 0.3914 - val_loss: 1.9792 - val_acc: 0.2167\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4983 - acc: 0.3814 - val_loss: 1.9833 - val_acc: 0.2533\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4984 - acc: 0.3843 - val_loss: 2.0046 - val_acc: 0.2300\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4982 - acc: 0.3771 - val_loss: 1.9696 - val_acc: 0.2300\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4977 - acc: 0.3814 - val_loss: 1.9811 - val_acc: 0.2467\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4990 - acc: 0.3786 - val_loss: 1.9880 - val_acc: 0.2333\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4974 - acc: 0.3843 - val_loss: 1.9760 - val_acc: 0.2233\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.4967 - acc: 0.3814 - val_loss: 1.9850 - val_acc: 0.2367\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4976 - acc: 0.3743 - val_loss: 1.9881 - val_acc: 0.2233\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4957 - acc: 0.3900 - val_loss: 1.9819 - val_acc: 0.2267\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4975 - acc: 0.3843 - val_loss: 1.9691 - val_acc: 0.2233\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4957 - acc: 0.3943 - val_loss: 1.9951 - val_acc: 0.2200\n",
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4948 - acc: 0.3857 - val_loss: 1.9635 - val_acc: 0.2300\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4946 - acc: 0.3771 - val_loss: 1.9781 - val_acc: 0.2233\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.4960 - acc: 0.3800 - val_loss: 1.9796 - val_acc: 0.2300\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4951 - acc: 0.3886 - val_loss: 1.9825 - val_acc: 0.2300\n",
      "Epoch 442/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4944 - acc: 0.3829 - val_loss: 1.9939 - val_acc: 0.2233\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4937 - acc: 0.3857 - val_loss: 1.9899 - val_acc: 0.2400\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4946 - acc: 0.3829 - val_loss: 1.9926 - val_acc: 0.2233\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4942 - acc: 0.3829 - val_loss: 1.9955 - val_acc: 0.2300\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4931 - acc: 0.3886 - val_loss: 2.0029 - val_acc: 0.2267\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4926 - acc: 0.3800 - val_loss: 2.0142 - val_acc: 0.2300\n",
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4927 - acc: 0.3843 - val_loss: 1.9924 - val_acc: 0.2267\n",
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4918 - acc: 0.3886 - val_loss: 2.0006 - val_acc: 0.2333\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4929 - acc: 0.3843 - val_loss: 1.9930 - val_acc: 0.2233\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4919 - acc: 0.3843 - val_loss: 1.9986 - val_acc: 0.2233\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4908 - acc: 0.3857 - val_loss: 1.9947 - val_acc: 0.2300\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4910 - acc: 0.3871 - val_loss: 1.9899 - val_acc: 0.2333\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4908 - acc: 0.3871 - val_loss: 1.9967 - val_acc: 0.2333\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4907 - acc: 0.3843 - val_loss: 1.9881 - val_acc: 0.2233\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4898 - acc: 0.3786 - val_loss: 1.9915 - val_acc: 0.2467\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4899 - acc: 0.3871 - val_loss: 1.9972 - val_acc: 0.2333\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4902 - acc: 0.3857 - val_loss: 1.9926 - val_acc: 0.2267\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4881 - acc: 0.3943 - val_loss: 1.9909 - val_acc: 0.2433\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4900 - acc: 0.3886 - val_loss: 2.0007 - val_acc: 0.2300\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4883 - acc: 0.3957 - val_loss: 2.0033 - val_acc: 0.2300\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4883 - acc: 0.3900 - val_loss: 1.9937 - val_acc: 0.2267\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4872 - acc: 0.3857 - val_loss: 2.0002 - val_acc: 0.2467\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4871 - acc: 0.3871 - val_loss: 1.9888 - val_acc: 0.2333\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4877 - acc: 0.3900 - val_loss: 1.9972 - val_acc: 0.2233\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4871 - acc: 0.3757 - val_loss: 2.0004 - val_acc: 0.2267\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4873 - acc: 0.3871 - val_loss: 2.0061 - val_acc: 0.2300\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4865 - acc: 0.3829 - val_loss: 1.9905 - val_acc: 0.2267\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4859 - acc: 0.3871 - val_loss: 2.0313 - val_acc: 0.2333\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4871 - acc: 0.3871 - val_loss: 2.0096 - val_acc: 0.2233\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4859 - acc: 0.3957 - val_loss: 2.0055 - val_acc: 0.2267\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4845 - acc: 0.3971 - val_loss: 2.0080 - val_acc: 0.2367\n",
      "Epoch 473/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4850 - acc: 0.3914 - val_loss: 2.0121 - val_acc: 0.2367\n",
      "Epoch 474/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 112us/step - loss: 1.4838 - acc: 0.3900 - val_loss: 1.9976 - val_acc: 0.2267\n",
      "Epoch 475/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4842 - acc: 0.3900 - val_loss: 2.0047 - val_acc: 0.2233\n",
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4835 - acc: 0.3900 - val_loss: 2.0056 - val_acc: 0.2267\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4839 - acc: 0.3900 - val_loss: 2.0095 - val_acc: 0.2267\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4838 - acc: 0.3929 - val_loss: 2.0056 - val_acc: 0.2333\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4833 - acc: 0.3900 - val_loss: 2.0015 - val_acc: 0.2300\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4824 - acc: 0.3957 - val_loss: 2.0102 - val_acc: 0.2367\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4821 - acc: 0.3871 - val_loss: 2.0187 - val_acc: 0.2400\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4810 - acc: 0.3986 - val_loss: 2.0164 - val_acc: 0.2300\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4821 - acc: 0.4000 - val_loss: 2.0144 - val_acc: 0.2367\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4815 - acc: 0.3986 - val_loss: 2.0162 - val_acc: 0.2400\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4811 - acc: 0.4029 - val_loss: 2.0154 - val_acc: 0.2300\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4808 - acc: 0.3857 - val_loss: 2.0074 - val_acc: 0.2467\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4811 - acc: 0.3957 - val_loss: 2.0075 - val_acc: 0.2500\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4808 - acc: 0.3914 - val_loss: 2.0157 - val_acc: 0.2500\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4804 - acc: 0.3886 - val_loss: 2.0031 - val_acc: 0.2267\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4809 - acc: 0.3900 - val_loss: 2.0000 - val_acc: 0.2333\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4808 - acc: 0.3871 - val_loss: 2.0215 - val_acc: 0.2300\n",
      "Epoch 492/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4800 - acc: 0.3914 - val_loss: 2.0007 - val_acc: 0.2267\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4799 - acc: 0.4014 - val_loss: 2.0076 - val_acc: 0.2333\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4802 - acc: 0.3900 - val_loss: 2.0072 - val_acc: 0.2233\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4792 - acc: 0.4029 - val_loss: 2.0260 - val_acc: 0.2333\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4786 - acc: 0.3857 - val_loss: 2.0112 - val_acc: 0.2433\n",
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4773 - acc: 0.3929 - val_loss: 2.0122 - val_acc: 0.2467\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4763 - acc: 0.3886 - val_loss: 2.0468 - val_acc: 0.2367\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4775 - acc: 0.4014 - val_loss: 2.0281 - val_acc: 0.2367\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4780 - acc: 0.3929 - val_loss: 2.0262 - val_acc: 0.2367\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4782 - acc: 0.4000 - val_loss: 2.0258 - val_acc: 0.2300\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4760 - acc: 0.3943 - val_loss: 2.0261 - val_acc: 0.2267\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4766 - acc: 0.3957 - val_loss: 2.0202 - val_acc: 0.2267\n",
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4757 - acc: 0.3971 - val_loss: 2.0240 - val_acc: 0.2267\n",
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4754 - acc: 0.3957 - val_loss: 2.0196 - val_acc: 0.2400\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4754 - acc: 0.3986 - val_loss: 2.0154 - val_acc: 0.2300\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4769 - acc: 0.3986 - val_loss: 2.0225 - val_acc: 0.2233\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4750 - acc: 0.3900 - val_loss: 2.0240 - val_acc: 0.2267\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4744 - acc: 0.3943 - val_loss: 2.0373 - val_acc: 0.2333\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4745 - acc: 0.3914 - val_loss: 2.0230 - val_acc: 0.2233\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4737 - acc: 0.4029 - val_loss: 2.0154 - val_acc: 0.2267\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4739 - acc: 0.3971 - val_loss: 2.0106 - val_acc: 0.2467\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4732 - acc: 0.3986 - val_loss: 2.0137 - val_acc: 0.2433\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4727 - acc: 0.4000 - val_loss: 2.0268 - val_acc: 0.2267\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4734 - acc: 0.4014 - val_loss: 2.0250 - val_acc: 0.2300\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4741 - acc: 0.3957 - val_loss: 2.0273 - val_acc: 0.2267\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4706 - acc: 0.3929 - val_loss: 2.0338 - val_acc: 0.2500\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4740 - acc: 0.4000 - val_loss: 2.0342 - val_acc: 0.2267\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s 103us/step - loss: 1.4727 - acc: 0.4043 - val_loss: 2.0238 - val_acc: 0.2300\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4718 - acc: 0.3957 - val_loss: 2.0307 - val_acc: 0.2400\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.4713 - acc: 0.4129 - val_loss: 2.0126 - val_acc: 0.2333\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4725 - acc: 0.3986 - val_loss: 2.0341 - val_acc: 0.2267\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4721 - acc: 0.3929 - val_loss: 2.0293 - val_acc: 0.2267\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4711 - acc: 0.3986 - val_loss: 2.0230 - val_acc: 0.2333\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4696 - acc: 0.4000 - val_loss: 2.0285 - val_acc: 0.2467\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4711 - acc: 0.4029 - val_loss: 2.0247 - val_acc: 0.2267\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4702 - acc: 0.3929 - val_loss: 2.0259 - val_acc: 0.2300\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4694 - acc: 0.4029 - val_loss: 2.0291 - val_acc: 0.2267\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4681 - acc: 0.3943 - val_loss: 2.0337 - val_acc: 0.2267\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4686 - acc: 0.4000 - val_loss: 2.0412 - val_acc: 0.2267\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4689 - acc: 0.3957 - val_loss: 2.0247 - val_acc: 0.2433\n",
      "Epoch 532/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4690 - acc: 0.4014 - val_loss: 2.0352 - val_acc: 0.2433\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 130us/step - loss: 1.4685 - acc: 0.4000 - val_loss: 2.0311 - val_acc: 0.2300\n",
      "Epoch 534/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4688 - acc: 0.3971 - val_loss: 2.0267 - val_acc: 0.2300\n",
      "Epoch 535/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4673 - acc: 0.4043 - val_loss: 2.0499 - val_acc: 0.2433\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4671 - acc: 0.4043 - val_loss: 2.0468 - val_acc: 0.2267\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4676 - acc: 0.4029 - val_loss: 2.0293 - val_acc: 0.2300\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4672 - acc: 0.3957 - val_loss: 2.0361 - val_acc: 0.2367\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4691 - acc: 0.3943 - val_loss: 2.0313 - val_acc: 0.2267\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4678 - acc: 0.4014 - val_loss: 2.0397 - val_acc: 0.2267\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.4667 - acc: 0.4014 - val_loss: 2.0371 - val_acc: 0.2267\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4665 - acc: 0.4057 - val_loss: 2.0430 - val_acc: 0.2433\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4670 - acc: 0.4000 - val_loss: 2.0292 - val_acc: 0.2333\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4657 - acc: 0.3943 - val_loss: 2.0243 - val_acc: 0.2367\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4665 - acc: 0.4014 - val_loss: 2.0327 - val_acc: 0.2300\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4635 - acc: 0.4000 - val_loss: 2.0464 - val_acc: 0.2533\n",
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4657 - acc: 0.4000 - val_loss: 2.0517 - val_acc: 0.2400\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4643 - acc: 0.3971 - val_loss: 2.0295 - val_acc: 0.2300\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4647 - acc: 0.4043 - val_loss: 2.0262 - val_acc: 0.2333\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4638 - acc: 0.4000 - val_loss: 2.0388 - val_acc: 0.2300\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4647 - acc: 0.4000 - val_loss: 2.0365 - val_acc: 0.2300\n",
      "Epoch 552/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4632 - acc: 0.4086 - val_loss: 2.0365 - val_acc: 0.2333\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4654 - acc: 0.4000 - val_loss: 2.0342 - val_acc: 0.2300\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4630 - acc: 0.3986 - val_loss: 2.0435 - val_acc: 0.2300\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4637 - acc: 0.4057 - val_loss: 2.0446 - val_acc: 0.2400\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4621 - acc: 0.4000 - val_loss: 2.0385 - val_acc: 0.2467\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4614 - acc: 0.4114 - val_loss: 2.0554 - val_acc: 0.2500\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4631 - acc: 0.4029 - val_loss: 2.0380 - val_acc: 0.2333\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.4614 - acc: 0.4029 - val_loss: 2.0413 - val_acc: 0.2533\n",
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4612 - acc: 0.4014 - val_loss: 2.0446 - val_acc: 0.2567\n",
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4623 - acc: 0.4100 - val_loss: 2.0394 - val_acc: 0.2267\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4619 - acc: 0.4029 - val_loss: 2.0325 - val_acc: 0.2300\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4613 - acc: 0.4000 - val_loss: 2.0365 - val_acc: 0.2267\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4611 - acc: 0.4071 - val_loss: 2.0515 - val_acc: 0.2300\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4603 - acc: 0.4043 - val_loss: 2.0375 - val_acc: 0.2333\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4620 - acc: 0.4100 - val_loss: 2.0473 - val_acc: 0.2300\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4599 - acc: 0.4171 - val_loss: 2.0504 - val_acc: 0.2300\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4598 - acc: 0.4057 - val_loss: 2.0486 - val_acc: 0.2433\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4594 - acc: 0.4057 - val_loss: 2.0432 - val_acc: 0.2533\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4586 - acc: 0.4114 - val_loss: 2.0507 - val_acc: 0.2333\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4588 - acc: 0.4043 - val_loss: 2.0480 - val_acc: 0.2300\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4580 - acc: 0.4014 - val_loss: 2.0397 - val_acc: 0.2333\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4573 - acc: 0.4114 - val_loss: 2.0551 - val_acc: 0.2533\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4597 - acc: 0.4043 - val_loss: 2.0408 - val_acc: 0.2500\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4597 - acc: 0.4114 - val_loss: 2.0449 - val_acc: 0.2267\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4586 - acc: 0.3957 - val_loss: 2.0468 - val_acc: 0.2300\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4583 - acc: 0.4014 - val_loss: 2.0449 - val_acc: 0.2300\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4577 - acc: 0.4071 - val_loss: 2.0453 - val_acc: 0.2367\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4584 - acc: 0.4057 - val_loss: 2.0428 - val_acc: 0.2267\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4574 - acc: 0.4086 - val_loss: 2.0531 - val_acc: 0.2367\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4570 - acc: 0.4071 - val_loss: 2.0488 - val_acc: 0.2567\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4569 - acc: 0.4071 - val_loss: 2.0513 - val_acc: 0.2267\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4563 - acc: 0.4014 - val_loss: 2.0529 - val_acc: 0.2267\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4571 - acc: 0.4071 - val_loss: 2.0504 - val_acc: 0.2267\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4558 - acc: 0.4100 - val_loss: 2.0556 - val_acc: 0.2300\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4549 - acc: 0.4043 - val_loss: 2.0555 - val_acc: 0.2500\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4573 - acc: 0.4114 - val_loss: 2.0557 - val_acc: 0.2333\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4560 - acc: 0.4043 - val_loss: 2.0581 - val_acc: 0.2300\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4553 - acc: 0.4057 - val_loss: 2.0576 - val_acc: 0.2267\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4553 - acc: 0.4014 - val_loss: 2.0520 - val_acc: 0.2300\n",
      "Epoch 591/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4554 - acc: 0.4086 - val_loss: 2.0605 - val_acc: 0.2267\n",
      "Epoch 592/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 112us/step - loss: 1.4544 - acc: 0.4086 - val_loss: 2.0557 - val_acc: 0.2333\n",
      "Epoch 593/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4546 - acc: 0.4057 - val_loss: 2.0498 - val_acc: 0.2267\n",
      "Epoch 594/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4540 - acc: 0.4129 - val_loss: 2.0513 - val_acc: 0.2333\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4543 - acc: 0.4057 - val_loss: 2.0569 - val_acc: 0.2433\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4537 - acc: 0.4129 - val_loss: 2.0472 - val_acc: 0.2300\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4525 - acc: 0.4143 - val_loss: 2.0491 - val_acc: 0.2500\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4537 - acc: 0.3986 - val_loss: 2.0563 - val_acc: 0.2267\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4541 - acc: 0.4043 - val_loss: 2.0478 - val_acc: 0.2333\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4525 - acc: 0.4143 - val_loss: 2.0625 - val_acc: 0.2300\n",
      "Epoch 601/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4523 - acc: 0.4129 - val_loss: 2.0623 - val_acc: 0.2433\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4526 - acc: 0.4029 - val_loss: 2.0585 - val_acc: 0.2333\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s 155us/step - loss: 1.4527 - acc: 0.4114 - val_loss: 2.0504 - val_acc: 0.2400\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4525 - acc: 0.4029 - val_loss: 2.0489 - val_acc: 0.2433\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4516 - acc: 0.4057 - val_loss: 2.0553 - val_acc: 0.2367\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4517 - acc: 0.4100 - val_loss: 2.0474 - val_acc: 0.2333\n",
      "Epoch 607/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4518 - acc: 0.4100 - val_loss: 2.0580 - val_acc: 0.2300\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4515 - acc: 0.4071 - val_loss: 2.0504 - val_acc: 0.2367\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4500 - acc: 0.4157 - val_loss: 2.0635 - val_acc: 0.2567\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4507 - acc: 0.4129 - val_loss: 2.0636 - val_acc: 0.2333\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4508 - acc: 0.4129 - val_loss: 2.0608 - val_acc: 0.2367\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4506 - acc: 0.4086 - val_loss: 2.0591 - val_acc: 0.2433\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4505 - acc: 0.4086 - val_loss: 2.0601 - val_acc: 0.2300\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s 117us/step - loss: 1.4496 - acc: 0.4129 - val_loss: 2.0686 - val_acc: 0.2500\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4502 - acc: 0.4129 - val_loss: 2.0535 - val_acc: 0.2533\n",
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4495 - acc: 0.4129 - val_loss: 2.0732 - val_acc: 0.2333\n",
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4480 - acc: 0.4157 - val_loss: 2.0653 - val_acc: 0.2533\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4491 - acc: 0.4014 - val_loss: 2.0597 - val_acc: 0.2400\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4479 - acc: 0.4114 - val_loss: 2.0671 - val_acc: 0.2333\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4488 - acc: 0.4171 - val_loss: 2.0564 - val_acc: 0.2300\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4487 - acc: 0.4129 - val_loss: 2.0741 - val_acc: 0.2333\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4476 - acc: 0.4114 - val_loss: 2.0741 - val_acc: 0.2367\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4471 - acc: 0.4186 - val_loss: 2.0690 - val_acc: 0.2267\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4480 - acc: 0.4171 - val_loss: 2.0689 - val_acc: 0.2367\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4479 - acc: 0.4029 - val_loss: 2.0724 - val_acc: 0.2367\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4471 - acc: 0.4086 - val_loss: 2.0535 - val_acc: 0.2367\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4478 - acc: 0.4257 - val_loss: 2.0632 - val_acc: 0.2333\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4459 - acc: 0.4157 - val_loss: 2.0503 - val_acc: 0.2400\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4475 - acc: 0.4100 - val_loss: 2.0615 - val_acc: 0.2333\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4460 - acc: 0.4114 - val_loss: 2.0542 - val_acc: 0.2333\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.4468 - acc: 0.4114 - val_loss: 2.0818 - val_acc: 0.2400\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4467 - acc: 0.4086 - val_loss: 2.0750 - val_acc: 0.2400\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4455 - acc: 0.4143 - val_loss: 2.0829 - val_acc: 0.2367\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4457 - acc: 0.4129 - val_loss: 2.0715 - val_acc: 0.2333\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4444 - acc: 0.4071 - val_loss: 2.0653 - val_acc: 0.2567\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4463 - acc: 0.4129 - val_loss: 2.0669 - val_acc: 0.2333\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4451 - acc: 0.4114 - val_loss: 2.0764 - val_acc: 0.2367\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4452 - acc: 0.4114 - val_loss: 2.0816 - val_acc: 0.2300\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4449 - acc: 0.4086 - val_loss: 2.0820 - val_acc: 0.2233\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4441 - acc: 0.4157 - val_loss: 2.0581 - val_acc: 0.2367\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4437 - acc: 0.4143 - val_loss: 2.0742 - val_acc: 0.2467\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4448 - acc: 0.4100 - val_loss: 2.0819 - val_acc: 0.2433\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4439 - acc: 0.4129 - val_loss: 2.0856 - val_acc: 0.2300\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4440 - acc: 0.4129 - val_loss: 2.0722 - val_acc: 0.2367\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4432 - acc: 0.4186 - val_loss: 2.0797 - val_acc: 0.2333\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4414 - acc: 0.4114 - val_loss: 2.0734 - val_acc: 0.2567\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4423 - acc: 0.4114 - val_loss: 2.0704 - val_acc: 0.2367\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4431 - acc: 0.4100 - val_loss: 2.0860 - val_acc: 0.2333\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4415 - acc: 0.4057 - val_loss: 2.0823 - val_acc: 0.2333\n",
      "Epoch 650/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4432 - acc: 0.4143 - val_loss: 2.0725 - val_acc: 0.2333\n",
      "Epoch 651/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 141us/step - loss: 1.4418 - acc: 0.4157 - val_loss: 2.0891 - val_acc: 0.2400\n",
      "Epoch 652/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4430 - acc: 0.4114 - val_loss: 2.0737 - val_acc: 0.2333\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4415 - acc: 0.4171 - val_loss: 2.0781 - val_acc: 0.2433\n",
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4414 - acc: 0.4143 - val_loss: 2.0641 - val_acc: 0.2467\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.4406 - acc: 0.4100 - val_loss: 2.0746 - val_acc: 0.2533\n",
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4426 - acc: 0.4086 - val_loss: 2.0850 - val_acc: 0.2433\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4409 - acc: 0.4186 - val_loss: 2.0809 - val_acc: 0.2300\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4409 - acc: 0.4143 - val_loss: 2.0781 - val_acc: 0.2367\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4404 - acc: 0.4186 - val_loss: 2.0800 - val_acc: 0.2467\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4409 - acc: 0.4100 - val_loss: 2.0796 - val_acc: 0.2367\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4418 - acc: 0.4086 - val_loss: 2.0753 - val_acc: 0.2367\n",
      "Epoch 662/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4410 - acc: 0.4000 - val_loss: 2.0794 - val_acc: 0.2367\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4402 - acc: 0.4157 - val_loss: 2.0953 - val_acc: 0.2400\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4394 - acc: 0.4186 - val_loss: 2.0829 - val_acc: 0.2400\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4396 - acc: 0.4114 - val_loss: 2.0887 - val_acc: 0.2333\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4390 - acc: 0.4200 - val_loss: 2.0808 - val_acc: 0.2533\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4406 - acc: 0.4114 - val_loss: 2.0751 - val_acc: 0.2367\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4375 - acc: 0.4157 - val_loss: 2.0902 - val_acc: 0.2567\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4382 - acc: 0.4157 - val_loss: 2.0931 - val_acc: 0.2333\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4393 - acc: 0.4171 - val_loss: 2.0815 - val_acc: 0.2333\n",
      "Epoch 671/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4377 - acc: 0.4157 - val_loss: 2.0801 - val_acc: 0.2533\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4382 - acc: 0.4100 - val_loss: 2.0893 - val_acc: 0.2367\n",
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4384 - acc: 0.4171 - val_loss: 2.0821 - val_acc: 0.2400\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4374 - acc: 0.4086 - val_loss: 2.1027 - val_acc: 0.2433\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s 101us/step - loss: 1.4366 - acc: 0.4214 - val_loss: 2.1019 - val_acc: 0.2533\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4370 - acc: 0.4186 - val_loss: 2.0800 - val_acc: 0.2567\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4360 - acc: 0.4143 - val_loss: 2.0972 - val_acc: 0.2300\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4355 - acc: 0.4200 - val_loss: 2.0724 - val_acc: 0.2333\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.4369 - acc: 0.4257 - val_loss: 2.0890 - val_acc: 0.2367\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.4377 - acc: 0.4157 - val_loss: 2.0891 - val_acc: 0.2400\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4370 - acc: 0.4186 - val_loss: 2.0805 - val_acc: 0.2400\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4360 - acc: 0.4214 - val_loss: 2.0854 - val_acc: 0.2567\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4356 - acc: 0.4129 - val_loss: 2.0779 - val_acc: 0.2500\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4330 - acc: 0.4143 - val_loss: 2.0887 - val_acc: 0.2600\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4356 - acc: 0.4143 - val_loss: 2.0846 - val_acc: 0.2567\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4352 - acc: 0.4200 - val_loss: 2.1067 - val_acc: 0.2533\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.4354 - acc: 0.4143 - val_loss: 2.0772 - val_acc: 0.2367\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4355 - acc: 0.4157 - val_loss: 2.0829 - val_acc: 0.2400\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4348 - acc: 0.4200 - val_loss: 2.0925 - val_acc: 0.2367\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4345 - acc: 0.4143 - val_loss: 2.0995 - val_acc: 0.2333\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4337 - acc: 0.4229 - val_loss: 2.0944 - val_acc: 0.2333\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.4339 - acc: 0.4186 - val_loss: 2.0823 - val_acc: 0.2400\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.4345 - acc: 0.4171 - val_loss: 2.0821 - val_acc: 0.2400\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4335 - acc: 0.4186 - val_loss: 2.1067 - val_acc: 0.2467\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.4348 - acc: 0.4171 - val_loss: 2.0871 - val_acc: 0.2567\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4324 - acc: 0.4214 - val_loss: 2.0991 - val_acc: 0.2333\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.4337 - acc: 0.4186 - val_loss: 2.1061 - val_acc: 0.2467\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4333 - acc: 0.4257 - val_loss: 2.0948 - val_acc: 0.2433\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4328 - acc: 0.4214 - val_loss: 2.0957 - val_acc: 0.2400\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4329 - acc: 0.4200 - val_loss: 2.0952 - val_acc: 0.2467\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4316 - acc: 0.4171 - val_loss: 2.0921 - val_acc: 0.2433\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4327 - acc: 0.4129 - val_loss: 2.0981 - val_acc: 0.2367\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4316 - acc: 0.4229 - val_loss: 2.1061 - val_acc: 0.2333\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4325 - acc: 0.4214 - val_loss: 2.0935 - val_acc: 0.2433\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4320 - acc: 0.4157 - val_loss: 2.0879 - val_acc: 0.2400\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4321 - acc: 0.4214 - val_loss: 2.0806 - val_acc: 0.2400\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4315 - acc: 0.4243 - val_loss: 2.0931 - val_acc: 0.2367\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4316 - acc: 0.4214 - val_loss: 2.0923 - val_acc: 0.2333\n",
      "Epoch 709/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4296 - acc: 0.4186 - val_loss: 2.1160 - val_acc: 0.2533\n",
      "Epoch 710/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 144us/step - loss: 1.4314 - acc: 0.4229 - val_loss: 2.0957 - val_acc: 0.2467\n",
      "Epoch 711/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4304 - acc: 0.4186 - val_loss: 2.0964 - val_acc: 0.2367\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4300 - acc: 0.4214 - val_loss: 2.1035 - val_acc: 0.2567\n",
      "Epoch 713/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4310 - acc: 0.4186 - val_loss: 2.0861 - val_acc: 0.2400\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4305 - acc: 0.4243 - val_loss: 2.0996 - val_acc: 0.2367\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4282 - acc: 0.4243 - val_loss: 2.0936 - val_acc: 0.2600\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s 97us/step - loss: 1.4305 - acc: 0.4157 - val_loss: 2.1060 - val_acc: 0.2367\n",
      "Epoch 717/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4297 - acc: 0.4157 - val_loss: 2.1014 - val_acc: 0.2367\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4289 - acc: 0.4186 - val_loss: 2.1246 - val_acc: 0.2533\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4303 - acc: 0.4186 - val_loss: 2.1100 - val_acc: 0.2400\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4295 - acc: 0.4214 - val_loss: 2.1052 - val_acc: 0.2367\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4291 - acc: 0.4200 - val_loss: 2.1038 - val_acc: 0.2433\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4286 - acc: 0.4200 - val_loss: 2.1045 - val_acc: 0.2367\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4282 - acc: 0.4214 - val_loss: 2.0911 - val_acc: 0.2400\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4281 - acc: 0.4257 - val_loss: 2.1101 - val_acc: 0.2367\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4277 - acc: 0.4229 - val_loss: 2.1167 - val_acc: 0.2433\n",
      "Epoch 726/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4278 - acc: 0.4257 - val_loss: 2.0962 - val_acc: 0.2367\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4273 - acc: 0.4214 - val_loss: 2.1264 - val_acc: 0.2333\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4276 - acc: 0.4200 - val_loss: 2.0961 - val_acc: 0.2400\n",
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4269 - acc: 0.4229 - val_loss: 2.1197 - val_acc: 0.2467\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4269 - acc: 0.4257 - val_loss: 2.1247 - val_acc: 0.2400\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4277 - acc: 0.4143 - val_loss: 2.1096 - val_acc: 0.2367\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4261 - acc: 0.4243 - val_loss: 2.1076 - val_acc: 0.2400\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4263 - acc: 0.4286 - val_loss: 2.1008 - val_acc: 0.2400\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4271 - acc: 0.4214 - val_loss: 2.1178 - val_acc: 0.2400\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4261 - acc: 0.4286 - val_loss: 2.1092 - val_acc: 0.2367\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4249 - acc: 0.4300 - val_loss: 2.1022 - val_acc: 0.2400\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4265 - acc: 0.4229 - val_loss: 2.1194 - val_acc: 0.2433\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4265 - acc: 0.4200 - val_loss: 2.1078 - val_acc: 0.2467\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4251 - acc: 0.4271 - val_loss: 2.1167 - val_acc: 0.2367\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4250 - acc: 0.4314 - val_loss: 2.1048 - val_acc: 0.2400\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4249 - acc: 0.4200 - val_loss: 2.1189 - val_acc: 0.2567\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4252 - acc: 0.4143 - val_loss: 2.1010 - val_acc: 0.2533\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4240 - acc: 0.4286 - val_loss: 2.1042 - val_acc: 0.2533\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4257 - acc: 0.4186 - val_loss: 2.1045 - val_acc: 0.2433\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4221 - acc: 0.4329 - val_loss: 2.1158 - val_acc: 0.2533\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4254 - acc: 0.4300 - val_loss: 2.1062 - val_acc: 0.2400\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4251 - acc: 0.4157 - val_loss: 2.1123 - val_acc: 0.2433\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4233 - acc: 0.4257 - val_loss: 2.1289 - val_acc: 0.2600\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s 105us/step - loss: 1.4222 - acc: 0.4271 - val_loss: 2.0960 - val_acc: 0.2333\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4239 - acc: 0.4329 - val_loss: 2.1004 - val_acc: 0.2300\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4224 - acc: 0.4171 - val_loss: 2.1130 - val_acc: 0.2400\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4233 - acc: 0.4243 - val_loss: 2.1173 - val_acc: 0.2367\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4223 - acc: 0.4257 - val_loss: 2.1337 - val_acc: 0.2333\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4235 - acc: 0.4271 - val_loss: 2.1186 - val_acc: 0.2333\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4221 - acc: 0.4386 - val_loss: 2.1169 - val_acc: 0.2467\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4223 - acc: 0.4143 - val_loss: 2.1151 - val_acc: 0.2400\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4233 - acc: 0.4200 - val_loss: 2.1210 - val_acc: 0.2433\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4220 - acc: 0.4300 - val_loss: 2.1190 - val_acc: 0.2433\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4221 - acc: 0.4271 - val_loss: 2.1112 - val_acc: 0.2400\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4218 - acc: 0.4329 - val_loss: 2.1117 - val_acc: 0.2400\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4215 - acc: 0.4229 - val_loss: 2.1349 - val_acc: 0.2500\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4225 - acc: 0.4257 - val_loss: 2.1261 - val_acc: 0.2400\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4215 - acc: 0.4200 - val_loss: 2.1152 - val_acc: 0.2400\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4227 - acc: 0.4300 - val_loss: 2.1314 - val_acc: 0.2433\n",
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.4203 - acc: 0.4214 - val_loss: 2.1405 - val_acc: 0.2333\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4217 - acc: 0.4214 - val_loss: 2.1154 - val_acc: 0.2400\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4217 - acc: 0.4257 - val_loss: 2.1160 - val_acc: 0.2367\n",
      "Epoch 768/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4205 - acc: 0.4257 - val_loss: 2.1068 - val_acc: 0.2400\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 121us/step - loss: 1.4207 - acc: 0.4243 - val_loss: 2.1165 - val_acc: 0.2367\n",
      "Epoch 770/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4200 - acc: 0.4214 - val_loss: 2.1088 - val_acc: 0.2333\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4196 - acc: 0.4214 - val_loss: 2.1229 - val_acc: 0.2367\n",
      "Epoch 772/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4202 - acc: 0.4229 - val_loss: 2.1255 - val_acc: 0.2433\n",
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4200 - acc: 0.4229 - val_loss: 2.1326 - val_acc: 0.2500\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4191 - acc: 0.4243 - val_loss: 2.1295 - val_acc: 0.2400\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4182 - acc: 0.4286 - val_loss: 2.1295 - val_acc: 0.2533\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4193 - acc: 0.4271 - val_loss: 2.1251 - val_acc: 0.2467\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4177 - acc: 0.4314 - val_loss: 2.1345 - val_acc: 0.2333\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4190 - acc: 0.4214 - val_loss: 2.1203 - val_acc: 0.2333\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4191 - acc: 0.4300 - val_loss: 2.1231 - val_acc: 0.2333\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4190 - acc: 0.4229 - val_loss: 2.1167 - val_acc: 0.2400\n",
      "Epoch 781/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4196 - acc: 0.4214 - val_loss: 2.1239 - val_acc: 0.2467\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4184 - acc: 0.4257 - val_loss: 2.1057 - val_acc: 0.2400\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4186 - acc: 0.4329 - val_loss: 2.1295 - val_acc: 0.2433\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4181 - acc: 0.4300 - val_loss: 2.1362 - val_acc: 0.2400\n",
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4179 - acc: 0.4271 - val_loss: 2.1419 - val_acc: 0.2367\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4180 - acc: 0.4271 - val_loss: 2.1251 - val_acc: 0.2467\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4184 - acc: 0.4243 - val_loss: 2.1135 - val_acc: 0.2500\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s 113us/step - loss: 1.4178 - acc: 0.4271 - val_loss: 2.1248 - val_acc: 0.2400\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4173 - acc: 0.4229 - val_loss: 2.1256 - val_acc: 0.2400\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4174 - acc: 0.4314 - val_loss: 2.1284 - val_acc: 0.2400\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4164 - acc: 0.4286 - val_loss: 2.1302 - val_acc: 0.2500\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s 120us/step - loss: 1.4171 - acc: 0.4229 - val_loss: 2.1204 - val_acc: 0.2367\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4166 - acc: 0.4257 - val_loss: 2.1365 - val_acc: 0.2500\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4169 - acc: 0.4271 - val_loss: 2.1308 - val_acc: 0.2367\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4164 - acc: 0.4314 - val_loss: 2.1278 - val_acc: 0.2400\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4160 - acc: 0.4300 - val_loss: 2.1290 - val_acc: 0.2367\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4164 - acc: 0.4200 - val_loss: 2.1355 - val_acc: 0.2367\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4162 - acc: 0.4386 - val_loss: 2.1362 - val_acc: 0.2400\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4152 - acc: 0.4329 - val_loss: 2.1291 - val_acc: 0.2567\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4159 - acc: 0.4200 - val_loss: 2.1378 - val_acc: 0.2333\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4159 - acc: 0.4329 - val_loss: 2.1350 - val_acc: 0.2333\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s 107us/step - loss: 1.4158 - acc: 0.4329 - val_loss: 2.1718 - val_acc: 0.2400\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.4146 - acc: 0.4271 - val_loss: 2.1338 - val_acc: 0.2600\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s 99us/step - loss: 1.4148 - acc: 0.4243 - val_loss: 2.1272 - val_acc: 0.2433\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4143 - acc: 0.4329 - val_loss: 2.1285 - val_acc: 0.2467\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4148 - acc: 0.4357 - val_loss: 2.1285 - val_acc: 0.2400\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4148 - acc: 0.4386 - val_loss: 2.1343 - val_acc: 0.2500\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s 110us/step - loss: 1.4143 - acc: 0.4314 - val_loss: 2.1340 - val_acc: 0.2400\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4150 - acc: 0.4229 - val_loss: 2.1349 - val_acc: 0.2467\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4139 - acc: 0.4357 - val_loss: 2.1360 - val_acc: 0.2367\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4142 - acc: 0.4314 - val_loss: 2.1368 - val_acc: 0.2400\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4141 - acc: 0.4271 - val_loss: 2.1262 - val_acc: 0.2400\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4139 - acc: 0.4329 - val_loss: 2.1430 - val_acc: 0.2400\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4131 - acc: 0.4286 - val_loss: 2.1356 - val_acc: 0.2533\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4139 - acc: 0.4314 - val_loss: 2.1410 - val_acc: 0.2467\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4136 - acc: 0.4300 - val_loss: 2.1348 - val_acc: 0.2367\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4116 - acc: 0.4300 - val_loss: 2.1359 - val_acc: 0.2367\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4123 - acc: 0.4286 - val_loss: 2.1431 - val_acc: 0.2367\n",
      "Epoch 819/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4110 - acc: 0.4357 - val_loss: 2.1535 - val_acc: 0.2600\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4131 - acc: 0.4329 - val_loss: 2.1379 - val_acc: 0.2567\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4129 - acc: 0.4300 - val_loss: 2.1497 - val_acc: 0.2467\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4130 - acc: 0.4329 - val_loss: 2.1381 - val_acc: 0.2367\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.4114 - acc: 0.4271 - val_loss: 2.1430 - val_acc: 0.2433\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.4110 - acc: 0.4300 - val_loss: 2.1438 - val_acc: 0.2433\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4112 - acc: 0.4314 - val_loss: 2.1583 - val_acc: 0.2467\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4122 - acc: 0.4271 - val_loss: 2.1483 - val_acc: 0.2467\n",
      "Epoch 827/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4112 - acc: 0.4300 - val_loss: 2.1481 - val_acc: 0.2400\n",
      "Epoch 828/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 127us/step - loss: 1.4118 - acc: 0.4343 - val_loss: 2.1369 - val_acc: 0.2367\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4111 - acc: 0.4314 - val_loss: 2.1411 - val_acc: 0.2433\n",
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4104 - acc: 0.4271 - val_loss: 2.1458 - val_acc: 0.2400\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4105 - acc: 0.4443 - val_loss: 2.1591 - val_acc: 0.2467\n",
      "Epoch 832/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4111 - acc: 0.4343 - val_loss: 2.1598 - val_acc: 0.2500\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4110 - acc: 0.4243 - val_loss: 2.1645 - val_acc: 0.2467\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.4106 - acc: 0.4329 - val_loss: 2.1743 - val_acc: 0.2433\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4095 - acc: 0.4300 - val_loss: 2.1435 - val_acc: 0.2367\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4098 - acc: 0.4271 - val_loss: 2.1518 - val_acc: 0.2500\n",
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4102 - acc: 0.4300 - val_loss: 2.1380 - val_acc: 0.2433\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4107 - acc: 0.4329 - val_loss: 2.1500 - val_acc: 0.2367\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4088 - acc: 0.4300 - val_loss: 2.1492 - val_acc: 0.2367\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4081 - acc: 0.4343 - val_loss: 2.1386 - val_acc: 0.2433\n",
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4092 - acc: 0.4371 - val_loss: 2.1470 - val_acc: 0.2367\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4098 - acc: 0.4271 - val_loss: 2.1594 - val_acc: 0.2500\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4090 - acc: 0.4314 - val_loss: 2.1469 - val_acc: 0.2367\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.4082 - acc: 0.4300 - val_loss: 2.1617 - val_acc: 0.2367\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.4088 - acc: 0.4314 - val_loss: 2.1402 - val_acc: 0.2367\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.4092 - acc: 0.4357 - val_loss: 2.1484 - val_acc: 0.2400\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.4075 - acc: 0.4229 - val_loss: 2.1584 - val_acc: 0.2433\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s 115us/step - loss: 1.4079 - acc: 0.4371 - val_loss: 2.1529 - val_acc: 0.2533\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.4086 - acc: 0.4300 - val_loss: 2.1555 - val_acc: 0.2433\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s 154us/step - loss: 1.4071 - acc: 0.4314 - val_loss: 2.1484 - val_acc: 0.2367\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.4071 - acc: 0.4229 - val_loss: 2.1482 - val_acc: 0.2333\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4086 - acc: 0.4371 - val_loss: 2.1509 - val_acc: 0.2433\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s 123us/step - loss: 1.4066 - acc: 0.4329 - val_loss: 2.1501 - val_acc: 0.2367\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4046 - acc: 0.4371 - val_loss: 2.1745 - val_acc: 0.2600\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4074 - acc: 0.4271 - val_loss: 2.1510 - val_acc: 0.2333\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.4074 - acc: 0.4357 - val_loss: 2.1598 - val_acc: 0.2500\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4067 - acc: 0.4286 - val_loss: 2.1580 - val_acc: 0.2467\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4066 - acc: 0.4343 - val_loss: 2.1567 - val_acc: 0.2367\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4052 - acc: 0.4357 - val_loss: 2.1554 - val_acc: 0.2367\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s 106us/step - loss: 1.4057 - acc: 0.4357 - val_loss: 2.1783 - val_acc: 0.2533\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4064 - acc: 0.4343 - val_loss: 2.1655 - val_acc: 0.2433\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4071 - acc: 0.4271 - val_loss: 2.1672 - val_acc: 0.2533\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.4055 - acc: 0.4329 - val_loss: 2.1677 - val_acc: 0.2500\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.4053 - acc: 0.4329 - val_loss: 2.1628 - val_acc: 0.2533\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4047 - acc: 0.4386 - val_loss: 2.1682 - val_acc: 0.2633\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.4049 - acc: 0.4314 - val_loss: 2.1387 - val_acc: 0.2433\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4052 - acc: 0.4357 - val_loss: 2.1681 - val_acc: 0.2433\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.4054 - acc: 0.4357 - val_loss: 2.1608 - val_acc: 0.2467\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4050 - acc: 0.4386 - val_loss: 2.1594 - val_acc: 0.2400\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.4034 - acc: 0.4357 - val_loss: 2.1720 - val_acc: 0.2467\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.4048 - acc: 0.4314 - val_loss: 2.1759 - val_acc: 0.2467\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.4037 - acc: 0.4357 - val_loss: 2.1607 - val_acc: 0.2567\n",
      "Epoch 873/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.4042 - acc: 0.4343 - val_loss: 2.1424 - val_acc: 0.2367\n",
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s 122us/step - loss: 1.4048 - acc: 0.4329 - val_loss: 2.1525 - val_acc: 0.2367\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.4038 - acc: 0.4329 - val_loss: 2.1739 - val_acc: 0.2467\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4035 - acc: 0.4314 - val_loss: 2.1520 - val_acc: 0.2433\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.4037 - acc: 0.4271 - val_loss: 2.1733 - val_acc: 0.2367\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.4042 - acc: 0.4343 - val_loss: 2.1688 - val_acc: 0.2400\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4012 - acc: 0.4371 - val_loss: 2.1696 - val_acc: 0.2400\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.4051 - acc: 0.4329 - val_loss: 2.1589 - val_acc: 0.2400\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.4035 - acc: 0.4429 - val_loss: 2.1855 - val_acc: 0.2500\n",
      "Epoch 882/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4035 - acc: 0.4371 - val_loss: 2.1721 - val_acc: 0.2400\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4044 - acc: 0.4286 - val_loss: 2.1476 - val_acc: 0.2400\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4027 - acc: 0.4314 - val_loss: 2.1799 - val_acc: 0.2533\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4031 - acc: 0.4314 - val_loss: 2.1444 - val_acc: 0.2433\n",
      "Epoch 886/1000\n",
      "700/700 [==============================] - 0s 112us/step - loss: 1.4036 - acc: 0.4386 - val_loss: 2.1664 - val_acc: 0.2467\n",
      "Epoch 887/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 130us/step - loss: 1.4026 - acc: 0.4371 - val_loss: 2.1546 - val_acc: 0.2367\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.4027 - acc: 0.4357 - val_loss: 2.1653 - val_acc: 0.2400\n",
      "Epoch 889/1000\n",
      "700/700 [==============================] - 0s 100us/step - loss: 1.4010 - acc: 0.4443 - val_loss: 2.1763 - val_acc: 0.2600\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.4028 - acc: 0.4386 - val_loss: 2.1675 - val_acc: 0.2567\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4024 - acc: 0.4271 - val_loss: 2.1707 - val_acc: 0.2433\n",
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.4024 - acc: 0.4357 - val_loss: 2.1736 - val_acc: 0.2433\n",
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.4018 - acc: 0.4357 - val_loss: 2.1794 - val_acc: 0.2433\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4020 - acc: 0.4429 - val_loss: 2.1670 - val_acc: 0.2400\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.4012 - acc: 0.4343 - val_loss: 2.1696 - val_acc: 0.2467\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.4014 - acc: 0.4357 - val_loss: 2.1745 - val_acc: 0.2600\n",
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.4017 - acc: 0.4343 - val_loss: 2.1688 - val_acc: 0.2533\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.4011 - acc: 0.4386 - val_loss: 2.1869 - val_acc: 0.2467\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.4015 - acc: 0.4343 - val_loss: 2.1634 - val_acc: 0.2467\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4001 - acc: 0.4471 - val_loss: 2.1660 - val_acc: 0.2467\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3999 - acc: 0.4400 - val_loss: 2.1780 - val_acc: 0.2533\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.4001 - acc: 0.4343 - val_loss: 2.1718 - val_acc: 0.2467\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3992 - acc: 0.4414 - val_loss: 2.1847 - val_acc: 0.2633\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3991 - acc: 0.4357 - val_loss: 2.1637 - val_acc: 0.2400\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.4010 - acc: 0.4400 - val_loss: 2.1595 - val_acc: 0.2400\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3998 - acc: 0.4371 - val_loss: 2.1560 - val_acc: 0.2367\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.4003 - acc: 0.4386 - val_loss: 2.1815 - val_acc: 0.2467\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3997 - acc: 0.4414 - val_loss: 2.1730 - val_acc: 0.2433\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s 108us/step - loss: 1.3993 - acc: 0.4329 - val_loss: 2.1789 - val_acc: 0.2500\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s 114us/step - loss: 1.4004 - acc: 0.4357 - val_loss: 2.1613 - val_acc: 0.2400\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3991 - acc: 0.4371 - val_loss: 2.1790 - val_acc: 0.2367\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3995 - acc: 0.4400 - val_loss: 2.1687 - val_acc: 0.2367\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.4000 - acc: 0.4371 - val_loss: 2.1881 - val_acc: 0.2433\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.3988 - acc: 0.4386 - val_loss: 2.1862 - val_acc: 0.2567\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.3990 - acc: 0.4343 - val_loss: 2.1746 - val_acc: 0.2467\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s 135us/step - loss: 1.3987 - acc: 0.4386 - val_loss: 2.1795 - val_acc: 0.2400\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.3978 - acc: 0.4400 - val_loss: 2.1797 - val_acc: 0.2400\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s 152us/step - loss: 1.3970 - acc: 0.4386 - val_loss: 2.1789 - val_acc: 0.2533\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.3984 - acc: 0.4329 - val_loss: 2.1871 - val_acc: 0.2433\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.3988 - acc: 0.4343 - val_loss: 2.1695 - val_acc: 0.2500\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.3984 - acc: 0.4357 - val_loss: 2.1721 - val_acc: 0.2400\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.3967 - acc: 0.4400 - val_loss: 2.1838 - val_acc: 0.2500\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3966 - acc: 0.4386 - val_loss: 2.1709 - val_acc: 0.2567\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.3988 - acc: 0.4414 - val_loss: 2.1766 - val_acc: 0.2467\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3970 - acc: 0.4343 - val_loss: 2.1822 - val_acc: 0.2367\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3972 - acc: 0.4443 - val_loss: 2.1771 - val_acc: 0.2467\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s 149us/step - loss: 1.3975 - acc: 0.4357 - val_loss: 2.1778 - val_acc: 0.2400\n",
      "Epoch 928/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.3971 - acc: 0.4400 - val_loss: 2.1921 - val_acc: 0.2433\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.3971 - acc: 0.4414 - val_loss: 2.1917 - val_acc: 0.2400\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3971 - acc: 0.4357 - val_loss: 2.1789 - val_acc: 0.2467\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3967 - acc: 0.4329 - val_loss: 2.1803 - val_acc: 0.2467\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s 131us/step - loss: 1.3962 - acc: 0.4400 - val_loss: 2.1716 - val_acc: 0.2500\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3966 - acc: 0.4314 - val_loss: 2.1818 - val_acc: 0.2467\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s 118us/step - loss: 1.3958 - acc: 0.4414 - val_loss: 2.1874 - val_acc: 0.2500\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s 129us/step - loss: 1.3966 - acc: 0.4414 - val_loss: 2.1846 - val_acc: 0.2500\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3965 - acc: 0.4429 - val_loss: 2.1883 - val_acc: 0.2500\n",
      "Epoch 937/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3960 - acc: 0.4400 - val_loss: 2.1831 - val_acc: 0.2367\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3953 - acc: 0.4443 - val_loss: 2.1899 - val_acc: 0.2500\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s 138us/step - loss: 1.3953 - acc: 0.4386 - val_loss: 2.1980 - val_acc: 0.2500\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s 136us/step - loss: 1.3960 - acc: 0.4343 - val_loss: 2.1790 - val_acc: 0.2400\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.3957 - acc: 0.4343 - val_loss: 2.1841 - val_acc: 0.2400\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3947 - acc: 0.4357 - val_loss: 2.1692 - val_acc: 0.2333\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3955 - acc: 0.4414 - val_loss: 2.1922 - val_acc: 0.2433\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s 119us/step - loss: 1.3944 - acc: 0.4371 - val_loss: 2.1942 - val_acc: 0.2433\n",
      "Epoch 945/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.3947 - acc: 0.4329 - val_loss: 2.1898 - val_acc: 0.2500\n",
      "Epoch 946/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 131us/step - loss: 1.3945 - acc: 0.4329 - val_loss: 2.1833 - val_acc: 0.2467\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3939 - acc: 0.4414 - val_loss: 2.1935 - val_acc: 0.2533\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.3940 - acc: 0.4300 - val_loss: 2.1744 - val_acc: 0.2367\n",
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s 111us/step - loss: 1.3938 - acc: 0.4471 - val_loss: 2.1834 - val_acc: 0.2400\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.3929 - acc: 0.4386 - val_loss: 2.1845 - val_acc: 0.2367\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s 148us/step - loss: 1.3940 - acc: 0.4429 - val_loss: 2.1889 - val_acc: 0.2500\n",
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s 132us/step - loss: 1.3938 - acc: 0.4414 - val_loss: 2.1852 - val_acc: 0.2467\n",
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.3935 - acc: 0.4371 - val_loss: 2.1988 - val_acc: 0.2533\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s 126us/step - loss: 1.3940 - acc: 0.4471 - val_loss: 2.1858 - val_acc: 0.2567\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.3936 - acc: 0.4429 - val_loss: 2.1951 - val_acc: 0.2500\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.3928 - acc: 0.4386 - val_loss: 2.2024 - val_acc: 0.2433\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.3925 - acc: 0.4414 - val_loss: 2.1847 - val_acc: 0.2433\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.3938 - acc: 0.4343 - val_loss: 2.2130 - val_acc: 0.2467\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.3936 - acc: 0.4414 - val_loss: 2.1808 - val_acc: 0.2467\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3930 - acc: 0.4400 - val_loss: 2.1918 - val_acc: 0.2467\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.3923 - acc: 0.4429 - val_loss: 2.1688 - val_acc: 0.2467\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3931 - acc: 0.4400 - val_loss: 2.1895 - val_acc: 0.2467\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s 145us/step - loss: 1.3926 - acc: 0.4386 - val_loss: 2.1845 - val_acc: 0.2500\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s 142us/step - loss: 1.3919 - acc: 0.4357 - val_loss: 2.1782 - val_acc: 0.2433\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3913 - acc: 0.4414 - val_loss: 2.1849 - val_acc: 0.2533\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.3924 - acc: 0.4429 - val_loss: 2.1969 - val_acc: 0.2567\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3923 - acc: 0.4429 - val_loss: 2.1947 - val_acc: 0.2467\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.3913 - acc: 0.4400 - val_loss: 2.1865 - val_acc: 0.2433\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.3917 - acc: 0.4414 - val_loss: 2.1907 - val_acc: 0.2433\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3916 - acc: 0.4400 - val_loss: 2.2006 - val_acc: 0.2400\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.3916 - acc: 0.4414 - val_loss: 2.1862 - val_acc: 0.2467\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s 124us/step - loss: 1.3913 - acc: 0.4386 - val_loss: 2.2011 - val_acc: 0.2333\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s 128us/step - loss: 1.3901 - acc: 0.4400 - val_loss: 2.1959 - val_acc: 0.2500\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s 116us/step - loss: 1.3908 - acc: 0.4386 - val_loss: 2.1971 - val_acc: 0.2500\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3907 - acc: 0.4443 - val_loss: 2.2058 - val_acc: 0.2500\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s 125us/step - loss: 1.3905 - acc: 0.4429 - val_loss: 2.1920 - val_acc: 0.2500\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3905 - acc: 0.4343 - val_loss: 2.1915 - val_acc: 0.2400\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s 144us/step - loss: 1.3904 - acc: 0.4486 - val_loss: 2.1936 - val_acc: 0.2533\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s 121us/step - loss: 1.3906 - acc: 0.4429 - val_loss: 2.1917 - val_acc: 0.2467\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.3906 - acc: 0.4429 - val_loss: 2.2041 - val_acc: 0.2500\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.3894 - acc: 0.4371 - val_loss: 2.2124 - val_acc: 0.2500\n",
      "Epoch 982/1000\n",
      "700/700 [==============================] - 0s 141us/step - loss: 1.3902 - acc: 0.4400 - val_loss: 2.1965 - val_acc: 0.2533\n",
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s 137us/step - loss: 1.3897 - acc: 0.4357 - val_loss: 2.2004 - val_acc: 0.2500\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s 147us/step - loss: 1.3898 - acc: 0.4414 - val_loss: 2.1945 - val_acc: 0.2500\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.3891 - acc: 0.4400 - val_loss: 2.2033 - val_acc: 0.2367\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.3891 - acc: 0.4414 - val_loss: 2.2010 - val_acc: 0.2500\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s 130us/step - loss: 1.3887 - acc: 0.4414 - val_loss: 2.1880 - val_acc: 0.2400\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s 140us/step - loss: 1.3886 - acc: 0.4429 - val_loss: 2.2116 - val_acc: 0.2633\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3903 - acc: 0.4357 - val_loss: 2.2104 - val_acc: 0.2533\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s 127us/step - loss: 1.3887 - acc: 0.4443 - val_loss: 2.2221 - val_acc: 0.2533\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.3890 - acc: 0.4471 - val_loss: 2.1938 - val_acc: 0.2433\n",
      "Epoch 992/1000\n",
      "700/700 [==============================] - 0s 153us/step - loss: 1.3888 - acc: 0.4371 - val_loss: 2.2048 - val_acc: 0.2400\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.3885 - acc: 0.4457 - val_loss: 2.2089 - val_acc: 0.2533\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s 150us/step - loss: 1.3885 - acc: 0.4357 - val_loss: 2.1919 - val_acc: 0.2367\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3890 - acc: 0.4429 - val_loss: 2.2041 - val_acc: 0.2500\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s 146us/step - loss: 1.3877 - acc: 0.4457 - val_loss: 2.2035 - val_acc: 0.2467\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s 143us/step - loss: 1.3879 - acc: 0.4429 - val_loss: 2.2026 - val_acc: 0.2533\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s 134us/step - loss: 1.3887 - acc: 0.4386 - val_loss: 2.2113 - val_acc: 0.2533\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s 133us/step - loss: 1.3881 - acc: 0.4386 - val_loss: 2.2013 - val_acc: 0.2500\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s 139us/step - loss: 1.3879 - acc: 0.4386 - val_loss: 2.2080 - val_acc: 0.2500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 훈련셋, 검증셋 고르기\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# 라벨링 전환\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 엮기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 모델 학습 과정 표시하기\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
